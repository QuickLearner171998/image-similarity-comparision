{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcvYoZiHJy5c"
   },
   "source": [
    "**Libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:28.905727Z",
     "iopub.status.busy": "2024-12-12T10:21:28.904728Z",
     "iopub.status.idle": "2024-12-12T10:21:28.911730Z",
     "shell.execute_reply": "2024-12-12T10:21:28.910769Z",
     "shell.execute_reply.started": "2024-12-12T10:21:28.905687Z"
    },
    "id": "LJlIHYjiI7pg",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms as T, models, utils\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHYAHK3nKmFC"
   },
   "source": [
    "**Path where to save and reload the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:28.914657Z",
     "iopub.status.busy": "2024-12-12T10:21:28.914118Z",
     "iopub.status.idle": "2024-12-12T10:21:28.924522Z",
     "shell.execute_reply": "2024-12-12T10:21:28.923548Z",
     "shell.execute_reply.started": "2024-12-12T10:21:28.914624Z"
    },
    "id": "zsdhJRJAKmVX",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PATH = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LybZPwy0J7kL"
   },
   "source": [
    "**FEW SHOT PARAMETERS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:28.926643Z",
     "iopub.status.busy": "2024-12-12T10:21:28.925974Z",
     "iopub.status.idle": "2024-12-12T10:21:28.935220Z",
     "shell.execute_reply": "2024-12-12T10:21:28.934486Z",
     "shell.execute_reply.started": "2024-12-12T10:21:28.926612Z"
    },
    "id": "DJRtEGB0KHrU",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "K_WAY = 10 # Means the support set has K classes, this classes are unseen during training, in this case We exclude K_WAY classes from the original dataset\n",
    "N_SHOT = 5 # Means every class has N sampes\n",
    "N_CLASS = 100 # for cifar100 = 100, cifar10 = 10 etc... if K_WAY == 0 the model learns every class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4s-qXoCKVg4"
   },
   "source": [
    "**Select Triplet Loss Function (Cosine Distance or Euclidean Distance):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:28.936567Z",
     "iopub.status.busy": "2024-12-12T10:21:28.936277Z",
     "iopub.status.idle": "2024-12-12T10:21:28.947893Z",
     "shell.execute_reply": "2024-12-12T10:21:28.947056Z",
     "shell.execute_reply.started": "2024-12-12T10:21:28.936543Z"
    },
    "id": "6yoDExvgKrtu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TRIPLET_COSINE = True #True cosine, False Euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPjISv8uLKaD"
   },
   "source": [
    "**Preprocessing dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:28.950305Z",
     "iopub.status.busy": "2024-12-12T10:21:28.949642Z",
     "iopub.status.idle": "2024-12-12T10:21:28.958950Z",
     "shell.execute_reply": "2024-12-12T10:21:28.958094Z",
     "shell.execute_reply.started": "2024-12-12T10:21:28.950272Z"
    },
    "id": "tYmmNmwtK-PT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MEAN = (0.4914, 0.4822, 0.4465)\n",
    "STD = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(MEAN, STD)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WDYuNMYUhGg"
   },
   "source": [
    "**Custom Arguments class:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:28.960725Z",
     "iopub.status.busy": "2024-12-12T10:21:28.960191Z",
     "iopub.status.idle": "2024-12-12T10:21:28.973195Z",
     "shell.execute_reply": "2024-12-12T10:21:28.972243Z",
     "shell.execute_reply.started": "2024-12-12T10:21:28.960697Z"
    },
    "id": "kkkT8ryBUgAS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#It's inconvenient to switch to the command line for colab, so I created my own args class\n",
    "class Arguments:\n",
    "    def __init__(self, batch_size=64, test_batch_size=1000, epochs=14, lr=0.001,\n",
    "                 no_cuda=False, no_mps=False, dry_run=False, seed=1,\n",
    "                 log_interval=10, save_model=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.test_batch_size = test_batch_size\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.no_cuda = no_cuda\n",
    "        self.no_mps = no_mps\n",
    "        self.dry_run = dry_run\n",
    "        self.seed = seed\n",
    "        self.log_interval = log_interval\n",
    "        self.save_model = save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wf2Bng2aLoOs"
   },
   "source": [
    "**ResNet optimized for cifar10/cifar100:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:28.975130Z",
     "iopub.status.busy": "2024-12-12T10:21:28.974795Z",
     "iopub.status.idle": "2024-12-12T10:21:28.989114Z",
     "shell.execute_reply": "2024-12-12T10:21:28.988307Z",
     "shell.execute_reply.started": "2024-12-12T10:21:28.975093Z"
    },
    "id": "0eX46b-lLsKX",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "                self.shortcut = nn.Sequential(\n",
    "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                     nn.BatchNorm2d(self.expansion * planes)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class SiameseNetwork(nn.Module): \n",
    "    def __init__(self, block = BasicBlock, num_blocks = [5, 5, 5]):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        output = out.view(out.size()[0], -1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzhY_pMEMJxv"
   },
   "source": [
    "**Loss Custom Implementation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:28.990388Z",
     "iopub.status.busy": "2024-12-12T10:21:28.990147Z",
     "iopub.status.idle": "2024-12-12T10:21:29.002854Z",
     "shell.execute_reply": "2024-12-12T10:21:29.001761Z",
     "shell.execute_reply.started": "2024-12-12T10:21:28.990364Z"
    },
    "id": "w9pJLr6qMSWB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TripletLoss_Cosine(nn.Module): \n",
    "    def __init__(self, margin=0.3):\n",
    "        super(TripletLoss_Cosine, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        cos_sim_pos = F.cosine_similarity(anchor, positive)\n",
    "        cos_sim_neg = F.cosine_similarity(anchor, negative)\n",
    "        loss = torch.relu(cos_sim_neg - cos_sim_pos + self.margin)\n",
    "        return loss.mean()\n",
    "\n",
    "class TripletLoss_Euclidean(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss_Euclidean, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist = (anchor - positive).pow(2).sum(1)\n",
    "        neg_dist = (anchor - negative).pow(2).sum(1)\n",
    "        loss = torch.relu(pos_dist - neg_dist + self.margin)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBQr0dFaNCEq"
   },
   "source": [
    "**Custom Matcher for binary test (img1, img2, label) (label = 1/0):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:29.115103Z",
     "iopub.status.busy": "2024-12-12T10:21:29.114516Z",
     "iopub.status.idle": "2024-12-12T10:21:29.125487Z",
     "shell.execute_reply": "2024-12-12T10:21:29.124620Z",
     "shell.execute_reply.started": "2024-12-12T10:21:29.115075Z"
    },
    "id": "Ga3FOjGLNC9F",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class APP_MATCHER_BINARY(Dataset):\n",
    "    def __init__(self, root, train, download=False):\n",
    "        super(APP_MATCHER_BINARY, self).__init__()\n",
    "        self.dataset = datasets.CIFAR100(root, train=train, download=download, transform=transform)\n",
    "        self.data = torch.stack([img for img, _ in self.dataset], dim=0)\n",
    "        self.group_examples()\n",
    "\n",
    "    def group_examples(self):\n",
    "        np_arr = np.array(self.dataset.targets)\n",
    "        self.grouped_examples = {}\n",
    "        for i in range(0, N_CLASS-K_WAY):\n",
    "            self.grouped_examples[i] = np.where((np_arr==i))[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        selected_class = random.randint(0, N_CLASS-K_WAY-1)\n",
    "        random_index_1 = random.randint(0, self.grouped_examples[selected_class].shape[0]-1)\n",
    "        index_1 = self.grouped_examples[selected_class][random_index_1]\n",
    "        image_1 = self.data[index_1].clone()\n",
    "\n",
    "        if index % 2 == 0:\n",
    "            random_index_2 = random.randint(0, self.grouped_examples[selected_class].shape[0]-1)\n",
    "            while random_index_2 == random_index_1:\n",
    "                random_index_2 = random.randint(0, self.grouped_examples[selected_class].shape[0]-1)\n",
    "            index_2 = self.grouped_examples[selected_class][random_index_2]\n",
    "            image_2 = self.data[index_2].clone()\n",
    "            target = torch.tensor(1, dtype=torch.float)\n",
    "        else:\n",
    "            other_selected_class = random.randint(0, N_CLASS-K_WAY-1)\n",
    "            while other_selected_class == selected_class:\n",
    "                other_selected_class = random.randint(0, N_CLASS-K_WAY-1)\n",
    "            random_index_2 = random.randint(0, self.grouped_examples[other_selected_class].shape[0]-1)\n",
    "            index_2 = self.grouped_examples[other_selected_class][random_index_2]\n",
    "            image_2 = self.data[index_2].clone()\n",
    "            target = torch.tensor(0, dtype=torch.float)\n",
    "\n",
    "        return image_1, image_2, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQitSFN0MggM"
   },
   "source": [
    "**Custom Matcher for triplet logic during train (Anchor, Positive, Negative)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:29.127597Z",
     "iopub.status.busy": "2024-12-12T10:21:29.127346Z",
     "iopub.status.idle": "2024-12-12T10:21:29.142785Z",
     "shell.execute_reply": "2024-12-12T10:21:29.141912Z",
     "shell.execute_reply.started": "2024-12-12T10:21:29.127573Z"
    },
    "id": "5AMKcfCPMq6W",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class APP_MATCHER(Dataset):\n",
    "    def __init__(self, root, train, download=False):\n",
    "        super(APP_MATCHER, self).__init__()\n",
    "        self.dataset = datasets.CIFAR100(root, train=train, download=download, transform=transform)\n",
    "        self.data = torch.stack([img for img, _ in self.dataset], dim=0)\n",
    "        self.group_examples()\n",
    "\n",
    "    def group_examples(self):\n",
    "        np_arr = np.array(self.dataset.targets)\n",
    "        self.grouped_examples = {}\n",
    "        for i in range(0, N_CLASS-K_WAY):\n",
    "            self.grouped_examples[i] = np.where((np_arr==i))[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        selected_class = random.randint(0, N_CLASS-K_WAY-1)\n",
    "        random_index_1 = random.randint(0, self.grouped_examples[selected_class].shape[0]-1)\n",
    "        index_1 = self.grouped_examples[selected_class][random_index_1]\n",
    "        anchor = self.data[index_1].clone()\n",
    "\n",
    "        random_index_2 = random.randint(0, self.grouped_examples[selected_class].shape[0]-1)\n",
    "        while random_index_2 == random_index_1:\n",
    "            random_index_2 = random.randint(0, self.grouped_examples[selected_class].shape[0]-1)\n",
    "        index_2 = self.grouped_examples[selected_class][random_index_2]\n",
    "        positive = self.data[index_2].clone()\n",
    "\n",
    "        other_selected_class = random.randint(0, N_CLASS-K_WAY-1)\n",
    "        while other_selected_class == selected_class:\n",
    "            other_selected_class = random.randint(0, N_CLASS-K_WAY-1)\n",
    "        random_index_2 = random.randint(0, self.grouped_examples[other_selected_class].shape[0]-1)\n",
    "        index_3 = self.grouped_examples[other_selected_class][random_index_2]\n",
    "        negative = self.data[index_3].clone()\n",
    "\n",
    "        return anchor, positive, negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfwdjWUWNmy5"
   },
   "source": [
    "**Custom Matcher for support_set and query_set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:29.144241Z",
     "iopub.status.busy": "2024-12-12T10:21:29.143992Z",
     "iopub.status.idle": "2024-12-12T10:21:29.154575Z",
     "shell.execute_reply": "2024-12-12T10:21:29.153907Z",
     "shell.execute_reply.started": "2024-12-12T10:21:29.144217Z"
    },
    "id": "CJ_Ek3M4Nl0j",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CIFAR100Subset(Dataset):\n",
    "    def __init__(self, root, train, download=False, few_shot_set=\"support\"):\n",
    "        super(CIFAR100Subset, self).__init__()\n",
    "        self.cifar100 = datasets.CIFAR100(root, train=train, download=download, transform = transform)\n",
    "\n",
    "        self.class_to_indices_support = {i: [] for i in range(N_CLASS-K_WAY, N_CLASS)}\n",
    "        self.class_to_indices_query = {i: [] for i in range(N_CLASS-K_WAY, N_CLASS)}\n",
    "\n",
    "        for idx, (_, class_idx) in enumerate(self.cifar100):\n",
    "            if class_idx in self.class_to_indices_support and len(self.class_to_indices_support[class_idx]) < N_SHOT:\n",
    "                self.class_to_indices_support[class_idx].append(idx)\n",
    "            elif class_idx in self.class_to_indices_support:\n",
    "                self.class_to_indices_query[class_idx].append(idx)\n",
    "\n",
    "        if few_shot_set == \"support\":\n",
    "            self.indices = [idx for indices in self.class_to_indices_support.values() for idx in indices]\n",
    "        elif few_shot_set == \"query\":\n",
    "            self.indices = [idx for indices in self.class_to_indices_query.values() for idx in indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.cifar100[self.indices[idx]]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5Idk7HdPCh9"
   },
   "source": [
    "**Train loop:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:21:29.156009Z",
     "iopub.status.busy": "2024-12-12T10:21:29.155678Z",
     "iopub.status.idle": "2024-12-12T10:21:29.171480Z",
     "shell.execute_reply": "2024-12-12T10:21:29.170442Z",
     "shell.execute_reply.started": "2024-12-12T10:21:29.155969Z"
    },
    "id": "PMoQx5n6PHbD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    if TRIPLET_COSINE:\n",
    "        criterion = TripletLoss_Cosine()\n",
    "    else:\n",
    "        criterion = TripletLoss_Euclidean()\n",
    "    for batch_idx, (anchor, positive, negative) in enumerate(train_loader):\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        anchor_output = model(anchor)\n",
    "        positive_output = model(positive)\n",
    "        negative_output = model(negative)\n",
    "        loss = criterion(anchor_output, positive_output, negative_output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(anchor), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "# Top-k accuracy evaluation:\n",
    "def top_k_accuracy(model, device, query_loader, support_loader, k=5):\n",
    "    class_embeddings = {}\n",
    "    model.eval()\n",
    "\n",
    "    # Compute embeddings for support set\n",
    "    with torch.no_grad():\n",
    "        for images, labels in support_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            embeddings = model(images)\n",
    "            for emb, label in zip(embeddings, labels):\n",
    "                if label.item() not in class_embeddings:\n",
    "                    class_embeddings[label.item()] = []\n",
    "                class_embeddings[label.item()].append(emb)\n",
    "\n",
    "    class_embeddings = {key: torch.stack(class_embeddings[key]) for key in class_embeddings}\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # compute embeddings for query set\n",
    "    with torch.no_grad():\n",
    "        for images, labels in query_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            embeddings = model(images)\n",
    "\n",
    "            for emb, label in zip(embeddings, labels):\n",
    "                distances = []\n",
    "                for class_label, class_embs in class_embeddings.items():\n",
    "                    if TRIPLET_COSINE:\n",
    "                        dist = torch.mean(1 - F.cosine_similarity(emb.unsqueeze(0), class_embs)).item()\n",
    "                    else:\n",
    "                        dist = torch.mean(torch.norm(emb.unsqueeze(0) - class_embs, dim=1)).item()\n",
    "                    distances.append((dist, class_label))\n",
    "\n",
    "                distances.sort()\n",
    "\n",
    "                top_k_classes = [label for _, label in distances[:k]]\n",
    "                if label.item() in top_k_classes:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    print('Top {:d} Accuracy: {:.2f}%'.format(k, accuracy))\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T10:23:05.220306Z",
     "iopub.status.busy": "2024-12-12T10:23:05.219931Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "- A pre-trained model was not found, I proceed with new training.\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.294399\n",
      "Train Epoch: 5 [1280/50000 (3%)]\tLoss: 0.266527\n",
      "Train Epoch: 5 [2560/50000 (5%)]\tLoss: 0.255358\n",
      "Train Epoch: 5 [3840/50000 (8%)]\tLoss: 0.225183\n",
      "Train Epoch: 5 [5120/50000 (10%)]\tLoss: 0.259398\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 0.218711\n",
      "Train Epoch: 5 [7680/50000 (15%)]\tLoss: 0.247596\n",
      "Train Epoch: 5 [8960/50000 (18%)]\tLoss: 0.186171\n",
      "Train Epoch: 5 [10240/50000 (20%)]\tLoss: 0.245858\n",
      "Train Epoch: 5 [11520/50000 (23%)]\tLoss: 0.209143\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.212677\n",
      "Train Epoch: 5 [14080/50000 (28%)]\tLoss: 0.218478\n",
      "Train Epoch: 5 [15360/50000 (31%)]\tLoss: 0.222595\n",
      "Train Epoch: 5 [16640/50000 (33%)]\tLoss: 0.220970\n",
      "Train Epoch: 5 [17920/50000 (36%)]\tLoss: 0.262666\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 0.217957\n",
      "Train Epoch: 5 [20480/50000 (41%)]\tLoss: 0.226872\n",
      "Train Epoch: 5 [21760/50000 (43%)]\tLoss: 0.231168\n",
      "Train Epoch: 5 [23040/50000 (46%)]\tLoss: 0.209812\n",
      "Train Epoch: 5 [24320/50000 (49%)]\tLoss: 0.217000\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.205148\n",
      "Train Epoch: 5 [26880/50000 (54%)]\tLoss: 0.211236\n",
      "Train Epoch: 5 [28160/50000 (56%)]\tLoss: 0.185078\n",
      "Train Epoch: 5 [29440/50000 (59%)]\tLoss: 0.219867\n",
      "Train Epoch: 5 [30720/50000 (61%)]\tLoss: 0.220347\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.233836\n",
      "Train Epoch: 5 [33280/50000 (66%)]\tLoss: 0.225698\n",
      "Train Epoch: 5 [34560/50000 (69%)]\tLoss: 0.229380\n",
      "Train Epoch: 5 [35840/50000 (72%)]\tLoss: 0.217939\n",
      "Train Epoch: 5 [37120/50000 (74%)]\tLoss: 0.188415\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.227630\n",
      "Train Epoch: 5 [39680/50000 (79%)]\tLoss: 0.230357\n",
      "Train Epoch: 5 [40960/50000 (82%)]\tLoss: 0.201925\n",
      "Train Epoch: 5 [42240/50000 (84%)]\tLoss: 0.232221\n",
      "Train Epoch: 5 [43520/50000 (87%)]\tLoss: 0.230209\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.201077\n",
      "Train Epoch: 5 [46080/50000 (92%)]\tLoss: 0.198678\n",
      "Train Epoch: 5 [47360/50000 (95%)]\tLoss: 0.192364\n",
      "Train Epoch: 5 [48640/50000 (97%)]\tLoss: 0.214653\n",
      "Train Epoch: 5 [31200/50000 (100%)]\tLoss: 0.216928\n",
      "Top 5 Accuracy: 81.16%\n",
      "- Best model saved with accuracy: 81.16%\n",
      "- Checkpoint saved successfully\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.191831\n",
      "Train Epoch: 6 [1280/50000 (3%)]\tLoss: 0.199809\n",
      "Train Epoch: 6 [2560/50000 (5%)]\tLoss: 0.196526\n",
      "Train Epoch: 6 [3840/50000 (8%)]\tLoss: 0.208410\n",
      "Train Epoch: 6 [5120/50000 (10%)]\tLoss: 0.193572\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 0.186825\n",
      "Train Epoch: 6 [7680/50000 (15%)]\tLoss: 0.211553\n",
      "Train Epoch: 6 [8960/50000 (18%)]\tLoss: 0.178490\n",
      "Train Epoch: 6 [10240/50000 (20%)]\tLoss: 0.211883\n",
      "Train Epoch: 6 [11520/50000 (23%)]\tLoss: 0.164785\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.210511\n",
      "Train Epoch: 6 [14080/50000 (28%)]\tLoss: 0.174385\n",
      "Train Epoch: 6 [15360/50000 (31%)]\tLoss: 0.185317\n",
      "Train Epoch: 6 [16640/50000 (33%)]\tLoss: 0.193812\n",
      "Train Epoch: 6 [17920/50000 (36%)]\tLoss: 0.263982\n",
      "Train Epoch: 6 [20480/50000 (41%)]\tLoss: 0.196357\n",
      "Train Epoch: 6 [21760/50000 (43%)]\tLoss: 0.195370\n",
      "Train Epoch: 6 [23040/50000 (46%)]\tLoss: 0.208055\n",
      "Train Epoch: 6 [24320/50000 (49%)]\tLoss: 0.213786\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.213359\n",
      "Train Epoch: 6 [26880/50000 (54%)]\tLoss: 0.190921\n",
      "Train Epoch: 6 [28160/50000 (56%)]\tLoss: 0.187095\n",
      "Train Epoch: 6 [29440/50000 (59%)]\tLoss: 0.177682\n",
      "Train Epoch: 6 [30720/50000 (61%)]\tLoss: 0.205619\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.182973\n",
      "Train Epoch: 6 [33280/50000 (66%)]\tLoss: 0.221639\n",
      "Train Epoch: 6 [34560/50000 (69%)]\tLoss: 0.148072\n",
      "Train Epoch: 6 [35840/50000 (72%)]\tLoss: 0.171038\n",
      "Train Epoch: 6 [37120/50000 (74%)]\tLoss: 0.184496\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.207624\n",
      "Train Epoch: 6 [39680/50000 (79%)]\tLoss: 0.187346\n",
      "Train Epoch: 6 [40960/50000 (82%)]\tLoss: 0.197135\n",
      "Train Epoch: 6 [42240/50000 (84%)]\tLoss: 0.203612\n",
      "Train Epoch: 6 [43520/50000 (87%)]\tLoss: 0.180598\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.179152\n",
      "Train Epoch: 6 [46080/50000 (92%)]\tLoss: 0.203440\n",
      "Train Epoch: 6 [47360/50000 (95%)]\tLoss: 0.159540\n",
      "Train Epoch: 6 [48640/50000 (97%)]\tLoss: 0.172144\n",
      "Train Epoch: 6 [31200/50000 (100%)]\tLoss: 0.185610\n",
      "Top 5 Accuracy: 79.05%\n",
      "- Early stopping trigger times: 1/10\n",
      "- Checkpoint saved successfully\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.168753\n",
      "Train Epoch: 7 [1280/50000 (3%)]\tLoss: 0.163276\n",
      "Train Epoch: 7 [2560/50000 (5%)]\tLoss: 0.184644\n",
      "Train Epoch: 7 [3840/50000 (8%)]\tLoss: 0.182237\n",
      "Train Epoch: 7 [5120/50000 (10%)]\tLoss: 0.160130\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.176793\n",
      "Train Epoch: 7 [7680/50000 (15%)]\tLoss: 0.187706\n",
      "Train Epoch: 7 [8960/50000 (18%)]\tLoss: 0.181325\n",
      "Train Epoch: 7 [10240/50000 (20%)]\tLoss: 0.188146\n",
      "Train Epoch: 7 [11520/50000 (23%)]\tLoss: 0.196909\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.186775\n",
      "Train Epoch: 7 [14080/50000 (28%)]\tLoss: 0.169791\n",
      "Train Epoch: 7 [15360/50000 (31%)]\tLoss: 0.168038\n",
      "Train Epoch: 7 [16640/50000 (33%)]\tLoss: 0.168887\n",
      "Train Epoch: 7 [17920/50000 (36%)]\tLoss: 0.183919\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.184500\n",
      "Train Epoch: 7 [20480/50000 (41%)]\tLoss: 0.168140\n",
      "Train Epoch: 7 [21760/50000 (43%)]\tLoss: 0.169973\n",
      "Train Epoch: 7 [23040/50000 (46%)]\tLoss: 0.173923\n",
      "Train Epoch: 7 [24320/50000 (49%)]\tLoss: 0.205706\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.174682\n",
      "Train Epoch: 7 [26880/50000 (54%)]\tLoss: 0.172145\n",
      "Train Epoch: 7 [28160/50000 (56%)]\tLoss: 0.175898\n",
      "Train Epoch: 7 [29440/50000 (59%)]\tLoss: 0.183152\n",
      "Train Epoch: 7 [30720/50000 (61%)]\tLoss: 0.157874\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.171696\n",
      "Train Epoch: 7 [33280/50000 (66%)]\tLoss: 0.187591\n",
      "Train Epoch: 7 [34560/50000 (69%)]\tLoss: 0.160312\n",
      "Train Epoch: 7 [35840/50000 (72%)]\tLoss: 0.186035\n",
      "Train Epoch: 7 [37120/50000 (74%)]\tLoss: 0.159901\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.176701\n",
      "Train Epoch: 7 [39680/50000 (79%)]\tLoss: 0.190524\n",
      "Train Epoch: 7 [40960/50000 (82%)]\tLoss: 0.166270\n",
      "Train Epoch: 7 [42240/50000 (84%)]\tLoss: 0.154135\n",
      "Train Epoch: 7 [43520/50000 (87%)]\tLoss: 0.166155\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.205839\n",
      "Train Epoch: 7 [46080/50000 (92%)]\tLoss: 0.166662\n",
      "Train Epoch: 7 [47360/50000 (95%)]\tLoss: 0.188525\n",
      "Train Epoch: 7 [48640/50000 (97%)]\tLoss: 0.188532\n",
      "Train Epoch: 7 [31200/50000 (100%)]\tLoss: 0.144480\n",
      "Top 5 Accuracy: 85.68%\n",
      "- Best model saved with accuracy: 85.68%\n",
      "- Checkpoint saved successfully\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.188993\n",
      "Train Epoch: 8 [1280/50000 (3%)]\tLoss: 0.177509\n",
      "Train Epoch: 8 [2560/50000 (5%)]\tLoss: 0.193404\n",
      "Train Epoch: 8 [3840/50000 (8%)]\tLoss: 0.137206\n",
      "Train Epoch: 8 [5120/50000 (10%)]\tLoss: 0.187858\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.183399\n",
      "Train Epoch: 8 [7680/50000 (15%)]\tLoss: 0.165898\n",
      "Train Epoch: 8 [8960/50000 (18%)]\tLoss: 0.171176\n",
      "Train Epoch: 8 [10240/50000 (20%)]\tLoss: 0.162727\n",
      "Train Epoch: 8 [11520/50000 (23%)]\tLoss: 0.186959\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.167676\n",
      "Train Epoch: 8 [14080/50000 (28%)]\tLoss: 0.172545\n",
      "Train Epoch: 8 [15360/50000 (31%)]\tLoss: 0.216691\n",
      "Train Epoch: 8 [16640/50000 (33%)]\tLoss: 0.194015\n",
      "Train Epoch: 8 [17920/50000 (36%)]\tLoss: 0.191524\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.159086\n",
      "Train Epoch: 8 [20480/50000 (41%)]\tLoss: 0.169296\n",
      "Train Epoch: 8 [21760/50000 (43%)]\tLoss: 0.214020\n",
      "Train Epoch: 8 [23040/50000 (46%)]\tLoss: 0.161671\n",
      "Train Epoch: 8 [24320/50000 (49%)]\tLoss: 0.147774\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.156568\n",
      "Train Epoch: 8 [26880/50000 (54%)]\tLoss: 0.164531\n",
      "Train Epoch: 8 [28160/50000 (56%)]\tLoss: 0.132274\n",
      "Train Epoch: 8 [29440/50000 (59%)]\tLoss: 0.182072\n",
      "Train Epoch: 8 [30720/50000 (61%)]\tLoss: 0.152287\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.196365\n",
      "Train Epoch: 8 [33280/50000 (66%)]\tLoss: 0.139700\n",
      "Train Epoch: 8 [34560/50000 (69%)]\tLoss: 0.169933\n",
      "Train Epoch: 8 [35840/50000 (72%)]\tLoss: 0.160868\n",
      "Train Epoch: 8 [37120/50000 (74%)]\tLoss: 0.166181\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.181382\n",
      "Train Epoch: 8 [39680/50000 (79%)]\tLoss: 0.175985\n",
      "Train Epoch: 8 [40960/50000 (82%)]\tLoss: 0.180268\n",
      "Train Epoch: 8 [42240/50000 (84%)]\tLoss: 0.179253\n",
      "Train Epoch: 8 [43520/50000 (87%)]\tLoss: 0.169371\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.208641\n",
      "Train Epoch: 8 [46080/50000 (92%)]\tLoss: 0.148533\n",
      "Train Epoch: 8 [47360/50000 (95%)]\tLoss: 0.188342\n",
      "Train Epoch: 8 [48640/50000 (97%)]\tLoss: 0.181233\n",
      "Train Epoch: 8 [31200/50000 (100%)]\tLoss: 0.183252\n",
      "Top 5 Accuracy: 86.95%\n",
      "- Best model saved with accuracy: 86.95%\n",
      "- Checkpoint saved successfully\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.140587\n",
      "Train Epoch: 9 [1280/50000 (3%)]\tLoss: 0.146313\n",
      "Train Epoch: 9 [2560/50000 (5%)]\tLoss: 0.161035\n",
      "Train Epoch: 9 [3840/50000 (8%)]\tLoss: 0.163816\n",
      "Train Epoch: 9 [5120/50000 (10%)]\tLoss: 0.166517\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.179870\n",
      "Train Epoch: 9 [7680/50000 (15%)]\tLoss: 0.180243\n",
      "Train Epoch: 9 [8960/50000 (18%)]\tLoss: 0.148255\n",
      "Train Epoch: 9 [10240/50000 (20%)]\tLoss: 0.146086\n",
      "Train Epoch: 9 [11520/50000 (23%)]\tLoss: 0.166461\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.158464\n",
      "Train Epoch: 9 [14080/50000 (28%)]\tLoss: 0.150638\n",
      "Train Epoch: 9 [15360/50000 (31%)]\tLoss: 0.181036\n",
      "Train Epoch: 9 [16640/50000 (33%)]\tLoss: 0.181026\n",
      "Train Epoch: 9 [17920/50000 (36%)]\tLoss: 0.193534\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.205655\n",
      "Train Epoch: 9 [20480/50000 (41%)]\tLoss: 0.131694\n",
      "Train Epoch: 9 [21760/50000 (43%)]\tLoss: 0.176987\n",
      "Train Epoch: 9 [23040/50000 (46%)]\tLoss: 0.141682\n",
      "Train Epoch: 9 [24320/50000 (49%)]\tLoss: 0.154198\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.167387\n",
      "Train Epoch: 9 [26880/50000 (54%)]\tLoss: 0.130063\n",
      "Train Epoch: 9 [28160/50000 (56%)]\tLoss: 0.145561\n",
      "Train Epoch: 9 [29440/50000 (59%)]\tLoss: 0.127993\n",
      "Train Epoch: 9 [30720/50000 (61%)]\tLoss: 0.159193\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.170527\n",
      "Train Epoch: 9 [33280/50000 (66%)]\tLoss: 0.137145\n",
      "Train Epoch: 9 [34560/50000 (69%)]\tLoss: 0.150455\n",
      "Train Epoch: 9 [35840/50000 (72%)]\tLoss: 0.154828\n",
      "Train Epoch: 9 [37120/50000 (74%)]\tLoss: 0.169487\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.173455\n",
      "Train Epoch: 9 [39680/50000 (79%)]\tLoss: 0.176295\n",
      "Train Epoch: 9 [40960/50000 (82%)]\tLoss: 0.129833\n",
      "Train Epoch: 9 [42240/50000 (84%)]\tLoss: 0.150447\n",
      "Train Epoch: 9 [43520/50000 (87%)]\tLoss: 0.115385\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.150896\n",
      "Train Epoch: 9 [46080/50000 (92%)]\tLoss: 0.191428\n",
      "Train Epoch: 9 [47360/50000 (95%)]\tLoss: 0.139113\n",
      "Train Epoch: 9 [48640/50000 (97%)]\tLoss: 0.131666\n",
      "Train Epoch: 9 [31200/50000 (100%)]\tLoss: 0.168205\n",
      "Top 5 Accuracy: 90.53%\n",
      "- Best model saved with accuracy: 90.53%\n",
      "- Checkpoint saved successfully\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.123523\n",
      "Train Epoch: 10 [1280/50000 (3%)]\tLoss: 0.179289\n",
      "Train Epoch: 10 [2560/50000 (5%)]\tLoss: 0.153050\n",
      "Train Epoch: 10 [3840/50000 (8%)]\tLoss: 0.127190\n",
      "Train Epoch: 10 [5120/50000 (10%)]\tLoss: 0.150489\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 0.164764\n",
      "Train Epoch: 10 [7680/50000 (15%)]\tLoss: 0.120689\n",
      "Train Epoch: 10 [8960/50000 (18%)]\tLoss: 0.144093\n",
      "Train Epoch: 10 [10240/50000 (20%)]\tLoss: 0.144272\n",
      "Train Epoch: 10 [11520/50000 (23%)]\tLoss: 0.171222\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.145433\n",
      "Train Epoch: 10 [14080/50000 (28%)]\tLoss: 0.172545\n",
      "Train Epoch: 10 [15360/50000 (31%)]\tLoss: 0.142910\n",
      "Train Epoch: 10 [16640/50000 (33%)]\tLoss: 0.159282\n",
      "Train Epoch: 10 [17920/50000 (36%)]\tLoss: 0.173011\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 0.135746\n",
      "Train Epoch: 10 [20480/50000 (41%)]\tLoss: 0.155647\n",
      "Train Epoch: 10 [21760/50000 (43%)]\tLoss: 0.161211\n",
      "Train Epoch: 10 [23040/50000 (46%)]\tLoss: 0.138057\n",
      "Train Epoch: 10 [24320/50000 (49%)]\tLoss: 0.135289\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.124775\n",
      "Train Epoch: 10 [26880/50000 (54%)]\tLoss: 0.137844\n",
      "Train Epoch: 10 [28160/50000 (56%)]\tLoss: 0.132221\n",
      "Train Epoch: 10 [29440/50000 (59%)]\tLoss: 0.135996\n",
      "Train Epoch: 10 [30720/50000 (61%)]\tLoss: 0.139619\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.159175\n",
      "Train Epoch: 10 [33280/50000 (66%)]\tLoss: 0.122232\n",
      "Train Epoch: 10 [34560/50000 (69%)]\tLoss: 0.158075\n",
      "Train Epoch: 10 [35840/50000 (72%)]\tLoss: 0.135372\n",
      "Train Epoch: 10 [37120/50000 (74%)]\tLoss: 0.178375\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.139158\n",
      "Train Epoch: 10 [39680/50000 (79%)]\tLoss: 0.136344\n",
      "Train Epoch: 10 [40960/50000 (82%)]\tLoss: 0.158863\n",
      "Train Epoch: 10 [42240/50000 (84%)]\tLoss: 0.121480\n",
      "Train Epoch: 10 [43520/50000 (87%)]\tLoss: 0.184065\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 0.135123\n",
      "Train Epoch: 10 [46080/50000 (92%)]\tLoss: 0.119412\n",
      "Train Epoch: 10 [47360/50000 (95%)]\tLoss: 0.114870\n",
      "Train Epoch: 10 [48640/50000 (97%)]\tLoss: 0.126962\n",
      "Train Epoch: 10 [31200/50000 (100%)]\tLoss: 0.173733\n",
      "Top 5 Accuracy: 90.32%\n",
      "- Early stopping trigger times: 1/10\n",
      "- Checkpoint saved successfully\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.155290\n",
      "Train Epoch: 11 [1280/50000 (3%)]\tLoss: 0.118535\n",
      "Train Epoch: 11 [2560/50000 (5%)]\tLoss: 0.137193\n",
      "Train Epoch: 11 [3840/50000 (8%)]\tLoss: 0.128451\n",
      "Train Epoch: 11 [5120/50000 (10%)]\tLoss: 0.115450\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 0.131278\n",
      "Train Epoch: 11 [7680/50000 (15%)]\tLoss: 0.160158\n",
      "Train Epoch: 11 [8960/50000 (18%)]\tLoss: 0.120552\n",
      "Train Epoch: 11 [10240/50000 (20%)]\tLoss: 0.162363\n",
      "Train Epoch: 11 [11520/50000 (23%)]\tLoss: 0.162646\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.176490\n",
      "Train Epoch: 11 [14080/50000 (28%)]\tLoss: 0.141389\n",
      "Train Epoch: 11 [15360/50000 (31%)]\tLoss: 0.147685\n",
      "Train Epoch: 11 [16640/50000 (33%)]\tLoss: 0.131489\n",
      "Train Epoch: 11 [17920/50000 (36%)]\tLoss: 0.106057\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 0.141963\n",
      "Train Epoch: 11 [20480/50000 (41%)]\tLoss: 0.164328\n",
      "Train Epoch: 11 [21760/50000 (43%)]\tLoss: 0.128466\n",
      "Train Epoch: 11 [23040/50000 (46%)]\tLoss: 0.129581\n",
      "Train Epoch: 11 [24320/50000 (49%)]\tLoss: 0.136709\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.132200\n",
      "Train Epoch: 11 [26880/50000 (54%)]\tLoss: 0.156528\n",
      "Train Epoch: 11 [28160/50000 (56%)]\tLoss: 0.106728\n",
      "Train Epoch: 11 [29440/50000 (59%)]\tLoss: 0.143555\n",
      "Train Epoch: 11 [30720/50000 (61%)]\tLoss: 0.121336\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 0.128278\n",
      "Train Epoch: 11 [33280/50000 (66%)]\tLoss: 0.119973\n",
      "Train Epoch: 11 [34560/50000 (69%)]\tLoss: 0.139645\n",
      "Train Epoch: 11 [35840/50000 (72%)]\tLoss: 0.164780\n",
      "Train Epoch: 11 [37120/50000 (74%)]\tLoss: 0.128231\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.136130\n",
      "Train Epoch: 11 [39680/50000 (79%)]\tLoss: 0.138205\n",
      "Train Epoch: 11 [40960/50000 (82%)]\tLoss: 0.131079\n",
      "Train Epoch: 11 [42240/50000 (84%)]\tLoss: 0.129299\n",
      "Train Epoch: 11 [43520/50000 (87%)]\tLoss: 0.142187\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 0.143932\n",
      "Train Epoch: 11 [46080/50000 (92%)]\tLoss: 0.142035\n",
      "Train Epoch: 11 [47360/50000 (95%)]\tLoss: 0.166619\n",
      "Train Epoch: 11 [48640/50000 (97%)]\tLoss: 0.151904\n",
      "Train Epoch: 11 [31200/50000 (100%)]\tLoss: 0.124860\n",
      "Top 5 Accuracy: 91.47%\n",
      "- Best model saved with accuracy: 91.47%\n",
      "- Checkpoint saved successfully\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.134063\n",
      "Train Epoch: 12 [1280/50000 (3%)]\tLoss: 0.137460\n",
      "Train Epoch: 12 [2560/50000 (5%)]\tLoss: 0.148412\n",
      "Train Epoch: 12 [3840/50000 (8%)]\tLoss: 0.138988\n",
      "Train Epoch: 12 [5120/50000 (10%)]\tLoss: 0.151802\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 0.140147\n",
      "Train Epoch: 12 [7680/50000 (15%)]\tLoss: 0.168187\n",
      "Train Epoch: 12 [8960/50000 (18%)]\tLoss: 0.125622\n",
      "Train Epoch: 12 [10240/50000 (20%)]\tLoss: 0.126905\n",
      "Train Epoch: 12 [11520/50000 (23%)]\tLoss: 0.154585\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.153079\n",
      "Train Epoch: 12 [14080/50000 (28%)]\tLoss: 0.161344\n",
      "Train Epoch: 12 [15360/50000 (31%)]\tLoss: 0.150566\n",
      "Train Epoch: 12 [16640/50000 (33%)]\tLoss: 0.125311\n",
      "Train Epoch: 12 [17920/50000 (36%)]\tLoss: 0.132176\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 0.117822\n",
      "Train Epoch: 12 [20480/50000 (41%)]\tLoss: 0.098043\n",
      "Train Epoch: 12 [21760/50000 (43%)]\tLoss: 0.134993\n",
      "Train Epoch: 12 [23040/50000 (46%)]\tLoss: 0.136431\n",
      "Train Epoch: 12 [24320/50000 (49%)]\tLoss: 0.121477\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.122417\n",
      "Train Epoch: 12 [26880/50000 (54%)]\tLoss: 0.133404\n",
      "Train Epoch: 12 [28160/50000 (56%)]\tLoss: 0.125654\n",
      "Train Epoch: 12 [29440/50000 (59%)]\tLoss: 0.167774\n",
      "Train Epoch: 12 [30720/50000 (61%)]\tLoss: 0.156327\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 0.128097\n",
      "Train Epoch: 12 [33280/50000 (66%)]\tLoss: 0.119763\n",
      "Train Epoch: 12 [34560/50000 (69%)]\tLoss: 0.141618\n",
      "Train Epoch: 12 [35840/50000 (72%)]\tLoss: 0.117844\n",
      "Train Epoch: 12 [37120/50000 (74%)]\tLoss: 0.135815\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.135534\n",
      "Train Epoch: 12 [39680/50000 (79%)]\tLoss: 0.144336\n",
      "Train Epoch: 12 [40960/50000 (82%)]\tLoss: 0.171737\n",
      "Train Epoch: 12 [42240/50000 (84%)]\tLoss: 0.090093\n",
      "Train Epoch: 12 [43520/50000 (87%)]\tLoss: 0.149888\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 0.134378\n",
      "Train Epoch: 12 [46080/50000 (92%)]\tLoss: 0.142668\n",
      "Train Epoch: 12 [47360/50000 (95%)]\tLoss: 0.125049\n",
      "Train Epoch: 12 [48640/50000 (97%)]\tLoss: 0.117461\n",
      "Train Epoch: 12 [31200/50000 (100%)]\tLoss: 0.138573\n",
      "Top 5 Accuracy: 92.32%\n",
      "- Best model saved with accuracy: 92.32%\n",
      "- Checkpoint saved successfully\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.142453\n",
      "Train Epoch: 13 [1280/50000 (3%)]\tLoss: 0.110770\n",
      "Train Epoch: 13 [2560/50000 (5%)]\tLoss: 0.102924\n",
      "Train Epoch: 13 [3840/50000 (8%)]\tLoss: 0.122097\n",
      "Train Epoch: 13 [5120/50000 (10%)]\tLoss: 0.102572\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 0.123971\n",
      "Train Epoch: 13 [7680/50000 (15%)]\tLoss: 0.149884\n",
      "Train Epoch: 13 [8960/50000 (18%)]\tLoss: 0.134809\n",
      "Train Epoch: 13 [10240/50000 (20%)]\tLoss: 0.135788\n",
      "Train Epoch: 13 [11520/50000 (23%)]\tLoss: 0.134592\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.142893\n",
      "Train Epoch: 13 [14080/50000 (28%)]\tLoss: 0.110479\n",
      "Train Epoch: 13 [15360/50000 (31%)]\tLoss: 0.110911\n",
      "Train Epoch: 13 [16640/50000 (33%)]\tLoss: 0.136430\n",
      "Train Epoch: 13 [17920/50000 (36%)]\tLoss: 0.106699\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 0.138813\n",
      "Train Epoch: 13 [20480/50000 (41%)]\tLoss: 0.132849\n",
      "Train Epoch: 13 [21760/50000 (43%)]\tLoss: 0.102275\n",
      "Train Epoch: 13 [23040/50000 (46%)]\tLoss: 0.116931\n",
      "Train Epoch: 13 [24320/50000 (49%)]\tLoss: 0.129498\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.142742\n",
      "Train Epoch: 13 [26880/50000 (54%)]\tLoss: 0.126302\n",
      "Train Epoch: 13 [28160/50000 (56%)]\tLoss: 0.124385\n",
      "Train Epoch: 13 [29440/50000 (59%)]\tLoss: 0.135489\n",
      "Train Epoch: 13 [30720/50000 (61%)]\tLoss: 0.135024\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 0.139532\n",
      "Train Epoch: 13 [33280/50000 (66%)]\tLoss: 0.164448\n",
      "Train Epoch: 13 [34560/50000 (69%)]\tLoss: 0.129579\n",
      "Train Epoch: 13 [35840/50000 (72%)]\tLoss: 0.139285\n",
      "Train Epoch: 13 [37120/50000 (74%)]\tLoss: 0.121552\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.126603\n",
      "Train Epoch: 13 [39680/50000 (79%)]\tLoss: 0.121673\n",
      "Train Epoch: 13 [40960/50000 (82%)]\tLoss: 0.155775\n",
      "Train Epoch: 13 [42240/50000 (84%)]\tLoss: 0.124240\n",
      "Train Epoch: 13 [43520/50000 (87%)]\tLoss: 0.119449\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 0.135116\n",
      "Train Epoch: 13 [46080/50000 (92%)]\tLoss: 0.113127\n",
      "Train Epoch: 13 [47360/50000 (95%)]\tLoss: 0.138560\n",
      "Train Epoch: 13 [48640/50000 (97%)]\tLoss: 0.123499\n",
      "Train Epoch: 13 [31200/50000 (100%)]\tLoss: 0.071828\n",
      "Top 5 Accuracy: 92.21%\n",
      "- Early stopping trigger times: 1/10\n",
      "- Checkpoint saved successfully\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.092420\n",
      "Train Epoch: 14 [1280/50000 (3%)]\tLoss: 0.133377\n",
      "Train Epoch: 14 [2560/50000 (5%)]\tLoss: 0.150686\n",
      "Train Epoch: 14 [3840/50000 (8%)]\tLoss: 0.101953\n",
      "Train Epoch: 14 [5120/50000 (10%)]\tLoss: 0.142121\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 0.100191\n",
      "Train Epoch: 14 [7680/50000 (15%)]\tLoss: 0.124345\n",
      "Train Epoch: 14 [8960/50000 (18%)]\tLoss: 0.124886\n",
      "Train Epoch: 14 [10240/50000 (20%)]\tLoss: 0.131706\n",
      "Train Epoch: 14 [11520/50000 (23%)]\tLoss: 0.093907\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.130004\n",
      "Train Epoch: 14 [14080/50000 (28%)]\tLoss: 0.112646\n",
      "Train Epoch: 14 [15360/50000 (31%)]\tLoss: 0.105185\n",
      "Train Epoch: 14 [16640/50000 (33%)]\tLoss: 0.138832\n",
      "Train Epoch: 14 [17920/50000 (36%)]\tLoss: 0.155332\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 0.142158\n",
      "Train Epoch: 14 [20480/50000 (41%)]\tLoss: 0.123779\n",
      "Train Epoch: 14 [21760/50000 (43%)]\tLoss: 0.100386\n",
      "Train Epoch: 14 [23040/50000 (46%)]\tLoss: 0.105856\n",
      "Train Epoch: 14 [24320/50000 (49%)]\tLoss: 0.095169\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.142097\n",
      "Train Epoch: 14 [26880/50000 (54%)]\tLoss: 0.110241\n",
      "Train Epoch: 14 [28160/50000 (56%)]\tLoss: 0.121532\n",
      "Train Epoch: 14 [29440/50000 (59%)]\tLoss: 0.136165\n",
      "Train Epoch: 14 [30720/50000 (61%)]\tLoss: 0.120359\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 0.136838\n",
      "Train Epoch: 14 [33280/50000 (66%)]\tLoss: 0.088411\n",
      "Train Epoch: 14 [34560/50000 (69%)]\tLoss: 0.114392\n",
      "Train Epoch: 14 [35840/50000 (72%)]\tLoss: 0.123973\n",
      "Train Epoch: 14 [37120/50000 (74%)]\tLoss: 0.094226\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.127175\n",
      "Train Epoch: 14 [39680/50000 (79%)]\tLoss: 0.102973\n",
      "Train Epoch: 14 [40960/50000 (82%)]\tLoss: 0.114852\n",
      "Train Epoch: 14 [42240/50000 (84%)]\tLoss: 0.091345\n",
      "Train Epoch: 14 [43520/50000 (87%)]\tLoss: 0.124460\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 0.130166\n",
      "Train Epoch: 14 [46080/50000 (92%)]\tLoss: 0.124547\n",
      "Train Epoch: 14 [47360/50000 (95%)]\tLoss: 0.107549\n",
      "Train Epoch: 14 [48640/50000 (97%)]\tLoss: 0.111736\n",
      "Train Epoch: 14 [31200/50000 (100%)]\tLoss: 0.111478\n",
      "Top 5 Accuracy: 91.79%\n",
      "- Early stopping trigger times: 2/10\n",
      "- Checkpoint saved successfully\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.118470\n",
      "Train Epoch: 15 [1280/50000 (3%)]\tLoss: 0.137370\n",
      "Train Epoch: 15 [2560/50000 (5%)]\tLoss: 0.147454\n",
      "Train Epoch: 15 [3840/50000 (8%)]\tLoss: 0.094839\n",
      "Train Epoch: 15 [5120/50000 (10%)]\tLoss: 0.102846\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 0.114565\n",
      "Train Epoch: 15 [7680/50000 (15%)]\tLoss: 0.136833\n",
      "Train Epoch: 15 [8960/50000 (18%)]\tLoss: 0.119874\n",
      "Train Epoch: 15 [10240/50000 (20%)]\tLoss: 0.124195\n",
      "Train Epoch: 15 [11520/50000 (23%)]\tLoss: 0.137875\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.132526\n",
      "Train Epoch: 15 [14080/50000 (28%)]\tLoss: 0.128232\n",
      "Train Epoch: 15 [15360/50000 (31%)]\tLoss: 0.099875\n",
      "Train Epoch: 15 [16640/50000 (33%)]\tLoss: 0.115932\n",
      "Train Epoch: 15 [17920/50000 (36%)]\tLoss: 0.117167\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 0.115108\n",
      "Train Epoch: 15 [20480/50000 (41%)]\tLoss: 0.100919\n",
      "Train Epoch: 15 [21760/50000 (43%)]\tLoss: 0.089683\n"
     ]
    }
   ],
   "source": [
    "# Load datasets:\n",
    "args = Arguments(batch_size=128, test_batch_size=1000, epochs=150, lr=0.001,\n",
    "                 no_cuda=False, no_mps=False, dry_run=False, seed=1,\n",
    "                 log_interval=10, save_model=True)\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "use_mps = not args.no_mps and torch.backends.mps.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "elif use_mps:\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "if(K_WAY > 0):\n",
    "    support_dataset = CIFAR100Subset('../data', train=False, download=True, few_shot_set = \"support\")\n",
    "    support_loader = torch.utils.data.DataLoader(support_dataset, batch_size=1)\n",
    "\n",
    "    query_dataset = CIFAR100Subset('../data', train=False, download=True, few_shot_set = \"query\")\n",
    "    query_loader = torch.utils.data.DataLoader(query_dataset, batch_size=args.test_batch_size, shuffle=True)\n",
    "\n",
    "train_dataset = APP_MATCHER('../data', train=True, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=args.batch_size)\n",
    "\n",
    "model = SiameseNetwork(num_blocks=[9, 9, 9]).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "n_epoch = 5\n",
    "\n",
    "if os.path.exists(PATH+\"siamese_network.pth\"):\n",
    "    checkpoint = torch.load(PATH+\"siamese_network.pth\")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    n_epoch = checkpoint['epoch']\n",
    "    print(\"- Checkpoint found, I resume training\")\n",
    "else:\n",
    "    print(\"- A pre-trained model was not found, I proceed with new training.\")\n",
    "\n",
    "\n",
    "# Let's Train:\n",
    "best_accuracy = 0\n",
    "patience = 10\n",
    "trigger_times = 0\n",
    "\n",
    "for epoch in range(n_epoch, args.epochs + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "\n",
    "    accuracy = top_k_accuracy(model, device, query_loader, support_loader, k=5)\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model_path = PATH + \"best_siamese_network.pth\"\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "        }, best_model_path)\n",
    "        print(f\"- Best model saved with accuracy: {best_accuracy:.2f}%\")\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        print(f\"- Early stopping trigger times: {trigger_times}/{patience}\")\n",
    "\n",
    "    if trigger_times >= patience:\n",
    "        print(\"- Early stopping\")\n",
    "        break\n",
    "\n",
    "    if args.save_model:\n",
    "        path = PATH + f\"siamese_network_{epoch}.pth\"\n",
    "        path_fast_load = PATH + f\"siamese_network.pth\"\n",
    "        checkpoint = {\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epoch': epoch + 1,\n",
    "        }\n",
    "        torch.save(checkpoint, path)\n",
    "        torch.save(checkpoint, path_fast_load)\n",
    "        print(\"- Checkpoint saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
