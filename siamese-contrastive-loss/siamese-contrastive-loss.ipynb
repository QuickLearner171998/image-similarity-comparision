{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Libraries:**","metadata":{"id":"VcvYoZiHJy5c"}},{"cell_type":"code","source":"import random\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.nn.init as init\nimport torchvision.utils as vutils\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets, transforms as T, models, utils\nfrom matplotlib import pyplot as plt","metadata":{"id":"LJlIHYjiI7pg","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:21:28.904728Z","iopub.execute_input":"2024-12-12T10:21:28.905727Z","iopub.status.idle":"2024-12-12T10:21:28.911730Z","shell.execute_reply.started":"2024-12-12T10:21:28.905687Z","shell.execute_reply":"2024-12-12T10:21:28.910769Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"**Path where to save and reload the model**","metadata":{"id":"NHYAHK3nKmFC"}},{"cell_type":"code","source":"PATH = './'","metadata":{"id":"zsdhJRJAKmVX","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:21:28.914118Z","iopub.execute_input":"2024-12-12T10:21:28.914657Z","iopub.status.idle":"2024-12-12T10:21:28.924522Z","shell.execute_reply.started":"2024-12-12T10:21:28.914624Z","shell.execute_reply":"2024-12-12T10:21:28.923548Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"**FEW SHOT PARAMETERS:**","metadata":{"id":"LybZPwy0J7kL"}},{"cell_type":"code","source":"K_WAY = 10 # Means the support set has K classes, this classes are unseen during training, in this case We exclude K_WAY classes from the original dataset\nN_SHOT = 5 # Means every class has N sampes\nN_CLASS = 100 # for cifar100 = 100, cifar10 = 10 etc... if K_WAY == 0 the model learns every class","metadata":{"id":"DJRtEGB0KHrU","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:21:28.925974Z","iopub.execute_input":"2024-12-12T10:21:28.926643Z","iopub.status.idle":"2024-12-12T10:21:28.935220Z","shell.execute_reply.started":"2024-12-12T10:21:28.926612Z","shell.execute_reply":"2024-12-12T10:21:28.934486Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"**Select Triplet Loss Function (Cosine Distance or Euclidean Distance):**","metadata":{"id":"X4s-qXoCKVg4"}},{"cell_type":"code","source":"TRIPLET_COSINE = True #True cosine, False Euclidean","metadata":{"id":"6yoDExvgKrtu","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:21:28.936277Z","iopub.execute_input":"2024-12-12T10:21:28.936567Z","iopub.status.idle":"2024-12-12T10:21:28.947893Z","shell.execute_reply.started":"2024-12-12T10:21:28.936543Z","shell.execute_reply":"2024-12-12T10:21:28.947056Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"**Preprocessing dataset:**","metadata":{"id":"gPjISv8uLKaD"}},{"cell_type":"code","source":"MEAN = (0.4914, 0.4822, 0.4465)\nSTD = (0.2023, 0.1994, 0.2010)\n\ntransform = T.Compose([\n    T.RandomHorizontalFlip(),\n    T.ToTensor(),\n    T.Normalize(MEAN, STD)\n])\n","metadata":{"id":"tYmmNmwtK-PT","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:21:28.949642Z","iopub.execute_input":"2024-12-12T10:21:28.950305Z","iopub.status.idle":"2024-12-12T10:21:28.958950Z","shell.execute_reply.started":"2024-12-12T10:21:28.950272Z","shell.execute_reply":"2024-12-12T10:21:28.958094Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"**Custom Arguments class:**","metadata":{"id":"5WDYuNMYUhGg"}},{"cell_type":"code","source":"#It's inconvenient to switch to the command line for colab, so I created my own args class\nclass Arguments:\n    def __init__(self, batch_size=64, test_batch_size=1000, epochs=14, lr=0.001,\n                 no_cuda=False, no_mps=False, dry_run=False, seed=1,\n                 log_interval=10, save_model=True):\n        self.batch_size = batch_size\n        self.test_batch_size = test_batch_size\n        self.epochs = epochs\n        self.lr = lr\n        self.no_cuda = no_cuda\n        self.no_mps = no_mps\n        self.dry_run = dry_run\n        self.seed = seed\n        self.log_interval = log_interval\n        self.save_model = save_model","metadata":{"id":"kkkT8ryBUgAS","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:21:28.960191Z","iopub.execute_input":"2024-12-12T10:21:28.960725Z","iopub.status.idle":"2024-12-12T10:21:28.973195Z","shell.execute_reply.started":"2024-12-12T10:21:28.960697Z","shell.execute_reply":"2024-12-12T10:21:28.972243Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"**ResNet optimized for cifar10/cifar100:**","metadata":{"id":"Wf2Bng2aLoOs"}},{"cell_type":"code","source":"def _weights_init(m):\n    classname = m.__class__.__name__\n    #print(classname)\n    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n        init.kaiming_normal_(m.weight)\n\nclass LambdaLayer(nn.Module):\n    def __init__(self, lambd):\n        super(LambdaLayer, self).__init__()\n        self.lambd = lambd\n\n    def forward(self, x):\n        return self.lambd(x)\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, option='A'):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            if option == 'A':\n                self.shortcut = LambdaLayer(lambda x:\n                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n            elif option == 'B':\n                self.shortcut = nn.Sequential(\n                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                     nn.BatchNorm2d(self.expansion * planes)\n                )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\nclass SiameseNetwork(nn.Module): \n    def __init__(self, block = BasicBlock, num_blocks = [5, 5, 5]):\n        super(SiameseNetwork, self).__init__()\n        self.in_planes = 16\n\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n\n        self.apply(_weights_init)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = F.avg_pool2d(out, out.size()[3])\n        output = out.view(out.size()[0], -1)\n\n        return output","metadata":{"id":"0eX46b-lLsKX","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:21:28.974795Z","iopub.execute_input":"2024-12-12T10:21:28.975130Z","iopub.status.idle":"2024-12-12T10:21:28.989114Z","shell.execute_reply.started":"2024-12-12T10:21:28.975093Z","shell.execute_reply":"2024-12-12T10:21:28.988307Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"**Loss Custom Implementation:**","metadata":{"id":"rzhY_pMEMJxv"}},{"cell_type":"code","source":"class TripletLoss_Cosine(nn.Module): \n    def __init__(self, margin=0.3):\n        super(TripletLoss_Cosine, self).__init__()\n        self.margin = margin\n\n    def forward(self, anchor, positive, negative):\n        cos_sim_pos = F.cosine_similarity(anchor, positive)\n        cos_sim_neg = F.cosine_similarity(anchor, negative)\n        loss = torch.relu(cos_sim_neg - cos_sim_pos + self.margin)\n        return loss.mean()\n\nclass TripletLoss_Euclidean(nn.Module):\n    def __init__(self, margin=1.0):\n        super(TripletLoss_Euclidean, self).__init__()\n        self.margin = margin\n\n    def forward(self, anchor, positive, negative):\n        pos_dist = (anchor - positive).pow(2).sum(1)\n        neg_dist = (anchor - negative).pow(2).sum(1)\n        loss = torch.relu(pos_dist - neg_dist + self.margin)\n        return loss.mean()","metadata":{"id":"w9pJLr6qMSWB","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:21:28.990147Z","iopub.execute_input":"2024-12-12T10:21:28.990388Z","iopub.status.idle":"2024-12-12T10:21:29.002854Z","shell.execute_reply.started":"2024-12-12T10:21:28.990364Z","shell.execute_reply":"2024-12-12T10:21:29.001761Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"**Custom Matcher for binary test (img1, img2, label) (label = 1/0):**","metadata":{"id":"TBQr0dFaNCEq"}},{"cell_type":"code","source":"class APP_MATCHER_BINARY(Dataset):\n    def __init__(self, root, train, download=False):\n        super(APP_MATCHER_BINARY, self).__init__()\n        self.dataset = datasets.CIFAR100(root, train=train, download=download, transform=transform)\n        self.data = torch.stack([img for img, _ in self.dataset], dim=0)\n        self.group_examples()\n\n    def group_examples(self):\n        np_arr = np.array(self.dataset.targets)\n        self.grouped_examples = {}\n        for i in range(0, N_CLASS-K_WAY):\n            self.grouped_examples[i] = np.where((np_arr==i))[0]\n\n    def __len__(self):\n        return self.data.shape[0]\n\n    def __getitem__(self, index):\n        selected_class = random.randint(0, N_CLASS-K_WAY-1)\n        random_index_1 = random.randint(0, self.grouped_examples[selected_class].shape[0]-1)\n        index_1 = self.grouped_examples[selected_class][random_index_1]\n        image_1 = self.data[index_1].clone()\n\n        if index % 2 == 0:\n            random_index_2 = random.randint(0, self.grouped_examples[selected_class].shape[0]-1)\n            while random_index_2 == random_index_1:\n                random_index_2 = random.randint(0, self.grouped_examples[selected_class].shape[0]-1)\n            index_2 = self.grouped_examples[selected_class][random_index_2]\n            image_2 = self.data[index_2].clone()\n            target = torch.tensor(1, dtype=torch.float)\n        else:\n            other_selected_class = random.randint(0, N_CLASS-K_WAY-1)\n            while other_selected_class == selected_class:\n                other_selected_class = random.randint(0, N_CLASS-K_WAY-1)\n            random_index_2 = random.randint(0, self.grouped_examples[other_selected_class].shape[0]-1)\n            index_2 = self.grouped_examples[other_selected_class][random_index_2]\n            image_2 = self.data[index_2].clone()\n            target = torch.tensor(0, dtype=torch.float)\n\n        return image_1, image_2, target","metadata":{"id":"Ga3FOjGLNC9F","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:21:29.114516Z","iopub.execute_input":"2024-12-12T10:21:29.115103Z","iopub.status.idle":"2024-12-12T10:21:29.125487Z","shell.execute_reply.started":"2024-12-12T10:21:29.115075Z","shell.execute_reply":"2024-12-12T10:21:29.124620Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"**Custom Matcher for triplet logic during train (Anchor, Positive, Negative)**:","metadata":{"id":"aQitSFN0MggM"}},{"cell_type":"code","source":"class APP_MATCHER(Dataset):\n    def __init__(self, root, train, download=False):\n        super(APP_MATCHER, self).__init__()\n        self.dataset = datasets.CIFAR100(root, train=train, download=download, transform=transform)\n        self.data = torch.stack([img for img, _ in self.dataset], dim=0)\n        self.group_examples()\n\n    def group_examples(self):\n        np_arr = np.array(self.dataset.targets)\n        self.grouped_examples = {}\n        for i in range(0, N_CLASS-K_WAY):\n            self.grouped_examples[i] = np.where((np_arr==i))[0]\n\n    def __len__(self):\n        return self.data.shape[0]\n\n    def __getitem__(self, index):\n        selected_class = random.randint(0, N_CLASS-K_WAY-1)\n        random_index_1 = random.randint(0, self.grouped_examples[selected_class].shape[0]-1)\n        index_1 = self.grouped_examples[selected_class][random_index_1]\n        anchor = self.data[index_1].clone()\n\n        random_index_2 = random.randint(0, self.grouped_examples[selected_class].shape[0]-1)\n        while random_index_2 == random_index_1:\n            random_index_2 = random.randint(0, self.grouped_examples[selected_class].shape[0]-1)\n        index_2 = self.grouped_examples[selected_class][random_index_2]\n        positive = self.data[index_2].clone()\n\n        other_selected_class = random.randint(0, N_CLASS-K_WAY-1)\n        while other_selected_class == selected_class:\n            other_selected_class = random.randint(0, N_CLASS-K_WAY-1)\n        random_index_2 = random.randint(0, self.grouped_examples[other_selected_class].shape[0]-1)\n        index_3 = self.grouped_examples[other_selected_class][random_index_2]\n        negative = self.data[index_3].clone()\n\n        return anchor, positive, negative","metadata":{"id":"5AMKcfCPMq6W","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:21:29.127346Z","iopub.execute_input":"2024-12-12T10:21:29.127597Z","iopub.status.idle":"2024-12-12T10:21:29.142785Z","shell.execute_reply.started":"2024-12-12T10:21:29.127573Z","shell.execute_reply":"2024-12-12T10:21:29.141912Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"**Custom Matcher for support_set and query_set:**","metadata":{"id":"rfwdjWUWNmy5"}},{"cell_type":"code","source":"class CIFAR100Subset(Dataset):\n    def __init__(self, root, train, download=False, few_shot_set=\"support\"):\n        super(CIFAR100Subset, self).__init__()\n        self.cifar100 = datasets.CIFAR100(root, train=train, download=download, transform = transform)\n\n        self.class_to_indices_support = {i: [] for i in range(N_CLASS-K_WAY, N_CLASS)}\n        self.class_to_indices_query = {i: [] for i in range(N_CLASS-K_WAY, N_CLASS)}\n\n        for idx, (_, class_idx) in enumerate(self.cifar100):\n            if class_idx in self.class_to_indices_support and len(self.class_to_indices_support[class_idx]) < N_SHOT:\n                self.class_to_indices_support[class_idx].append(idx)\n            elif class_idx in self.class_to_indices_support:\n                self.class_to_indices_query[class_idx].append(idx)\n\n        if few_shot_set == \"support\":\n            self.indices = [idx for indices in self.class_to_indices_support.values() for idx in indices]\n        elif few_shot_set == \"query\":\n            self.indices = [idx for indices in self.class_to_indices_query.values() for idx in indices]\n\n    def __len__(self):\n        return len(self.indices)\n\n    def __getitem__(self, idx):\n        image, label = self.cifar100[self.indices[idx]]\n        return image, label","metadata":{"id":"CJ_Ek3M4Nl0j","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:21:29.143992Z","iopub.execute_input":"2024-12-12T10:21:29.144241Z","iopub.status.idle":"2024-12-12T10:21:29.154575Z","shell.execute_reply.started":"2024-12-12T10:21:29.144217Z","shell.execute_reply":"2024-12-12T10:21:29.153907Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"**Train loop:**","metadata":{"id":"C5Idk7HdPCh9"}},{"cell_type":"code","source":"def train(args, model, device, train_loader, optimizer, epoch):\n    model.train()\n    if TRIPLET_COSINE:\n        criterion = TripletLoss_Cosine()\n    else:\n        criterion = TripletLoss_Euclidean()\n    for batch_idx, (anchor, positive, negative) in enumerate(train_loader):\n        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n        optimizer.zero_grad()\n        anchor_output = model(anchor)\n        positive_output = model(positive)\n        negative_output = model(negative)\n        loss = criterion(anchor_output, positive_output, negative_output)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(anchor), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n            if args.dry_run:\n                break\n\n# Top-k accuracy evaluation:\ndef top_k_accuracy(model, device, query_loader, support_loader, k=5):\n    class_embeddings = {}\n    model.eval()\n\n    # Compute embeddings for support set\n    with torch.no_grad():\n        for images, labels in support_loader:\n            images, labels = images.to(device), labels.to(device)\n            embeddings = model(images)\n            for emb, label in zip(embeddings, labels):\n                if label.item() not in class_embeddings:\n                    class_embeddings[label.item()] = []\n                class_embeddings[label.item()].append(emb)\n\n    class_embeddings = {key: torch.stack(class_embeddings[key]) for key in class_embeddings}\n\n    correct = 0\n    total = 0\n\n    # compute embeddings for query set\n    with torch.no_grad():\n        for images, labels in query_loader:\n            images, labels = images.to(device), labels.to(device)\n            embeddings = model(images)\n\n            for emb, label in zip(embeddings, labels):\n                distances = []\n                for class_label, class_embs in class_embeddings.items():\n                    if TRIPLET_COSINE:\n                        dist = torch.mean(1 - F.cosine_similarity(emb.unsqueeze(0), class_embs)).item()\n                    else:\n                        dist = torch.mean(torch.norm(emb.unsqueeze(0) - class_embs, dim=1)).item()\n                    distances.append((dist, class_label))\n\n                distances.sort()\n\n                top_k_classes = [label for _, label in distances[:k]]\n                if label.item() in top_k_classes:\n                    correct += 1\n                total += 1\n\n    accuracy = 100.0 * correct / total\n    print('Top {:d} Accuracy: {:.2f}%'.format(k, accuracy))\n    return accuracy\n\n","metadata":{"id":"PMoQx5n6PHbD","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:21:29.155678Z","iopub.execute_input":"2024-12-12T10:21:29.156009Z","iopub.status.idle":"2024-12-12T10:21:29.171480Z","shell.execute_reply.started":"2024-12-12T10:21:29.155969Z","shell.execute_reply":"2024-12-12T10:21:29.170442Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Load datasets:\nargs = Arguments(batch_size=128, test_batch_size=1000, epochs=150, lr=0.001,\n                 no_cuda=False, no_mps=False, dry_run=False, seed=1,\n                 log_interval=10, save_model=True)\n\nuse_cuda = not args.no_cuda and torch.cuda.is_available()\nuse_mps = not args.no_mps and torch.backends.mps.is_available()\n\ntorch.manual_seed(args.seed)\n\nif use_cuda:\n    device = torch.device(\"cuda\")\nelif use_mps:\n    device = torch.device(\"mps\")\nelse:\n    device = torch.device(\"cpu\")\n\nif(K_WAY > 0):\n    support_dataset = CIFAR100Subset('../data', train=False, download=True, few_shot_set = \"support\")\n    support_loader = torch.utils.data.DataLoader(support_dataset, batch_size=1)\n\n    query_dataset = CIFAR100Subset('../data', train=False, download=True, few_shot_set = \"query\")\n    query_loader = torch.utils.data.DataLoader(query_dataset, batch_size=args.test_batch_size, shuffle=True)\n\ntrain_dataset = APP_MATCHER('../data', train=True, download=True)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=args.batch_size)\n\nmodel = SiameseNetwork(num_blocks=[9, 9, 9]).to(device)\noptimizer = optim.Adam(model.parameters(), lr=args.lr)\nn_epoch = 5\n\nif os.path.exists(PATH+\"siamese_network.pth\"):\n    checkpoint = torch.load(PATH+\"siamese_network.pth\")\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    n_epoch = checkpoint['epoch']\n    print(\"- Checkpoint found, I resume training\")\nelse:\n    print(\"- A pre-trained model was not found, I proceed with new training.\")\n\n\n# Let's Train:\nbest_accuracy = 0\npatience = 10\ntrigger_times = 0\n\nfor epoch in range(n_epoch, args.epochs + 1):\n    train(args, model, device, train_loader, optimizer, epoch)\n\n    accuracy = top_k_accuracy(model, device, query_loader, support_loader, k=5)\n\n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n        best_model_path = PATH + \"best_siamese_network.pth\"\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'epoch': epoch,\n        }, best_model_path)\n        print(f\"- Best model saved with accuracy: {best_accuracy:.2f}%\")\n        trigger_times = 0\n    else:\n        trigger_times += 1\n        print(f\"- Early stopping trigger times: {trigger_times}/{patience}\")\n\n    if trigger_times >= patience:\n        print(\"- Early stopping\")\n        break\n\n    if args.save_model:\n        path = PATH + f\"siamese_network_{epoch}.pth\"\n        path_fast_load = PATH + f\"siamese_network.pth\"\n        checkpoint = {\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'epoch': epoch + 1,\n        }\n        torch.save(checkpoint, path)\n        torch.save(checkpoint, path_fast_load)\n        print(\"- Checkpoint saved successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:23:05.219931Z","iopub.execute_input":"2024-12-12T10:23:05.220306Z"}},"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nFiles already downloaded and verified\n- A pre-trained model was not found, I proceed with new training.\nTrain Epoch: 5 [0/50000 (0%)]\tLoss: 0.294399\nTrain Epoch: 5 [1280/50000 (3%)]\tLoss: 0.266527\nTrain Epoch: 5 [2560/50000 (5%)]\tLoss: 0.255358\nTrain Epoch: 5 [3840/50000 (8%)]\tLoss: 0.225183\nTrain Epoch: 5 [5120/50000 (10%)]\tLoss: 0.259398\nTrain Epoch: 5 [6400/50000 (13%)]\tLoss: 0.218711\nTrain Epoch: 5 [7680/50000 (15%)]\tLoss: 0.247596\nTrain Epoch: 5 [8960/50000 (18%)]\tLoss: 0.186171\nTrain Epoch: 5 [10240/50000 (20%)]\tLoss: 0.245858\nTrain Epoch: 5 [11520/50000 (23%)]\tLoss: 0.209143\nTrain Epoch: 5 [12800/50000 (26%)]\tLoss: 0.212677\nTrain Epoch: 5 [14080/50000 (28%)]\tLoss: 0.218478\nTrain Epoch: 5 [15360/50000 (31%)]\tLoss: 0.222595\nTrain Epoch: 5 [16640/50000 (33%)]\tLoss: 0.220970\nTrain Epoch: 5 [17920/50000 (36%)]\tLoss: 0.262666\nTrain Epoch: 5 [19200/50000 (38%)]\tLoss: 0.217957\nTrain Epoch: 5 [20480/50000 (41%)]\tLoss: 0.226872\nTrain Epoch: 5 [21760/50000 (43%)]\tLoss: 0.231168\nTrain Epoch: 5 [23040/50000 (46%)]\tLoss: 0.209812\nTrain Epoch: 5 [24320/50000 (49%)]\tLoss: 0.217000\nTrain Epoch: 5 [25600/50000 (51%)]\tLoss: 0.205148\nTrain Epoch: 5 [26880/50000 (54%)]\tLoss: 0.211236\nTrain Epoch: 5 [28160/50000 (56%)]\tLoss: 0.185078\nTrain Epoch: 5 [29440/50000 (59%)]\tLoss: 0.219867\nTrain Epoch: 5 [30720/50000 (61%)]\tLoss: 0.220347\nTrain Epoch: 5 [32000/50000 (64%)]\tLoss: 0.233836\nTrain Epoch: 5 [33280/50000 (66%)]\tLoss: 0.225698\nTrain Epoch: 5 [34560/50000 (69%)]\tLoss: 0.229380\nTrain Epoch: 5 [35840/50000 (72%)]\tLoss: 0.217939\nTrain Epoch: 5 [37120/50000 (74%)]\tLoss: 0.188415\nTrain Epoch: 5 [38400/50000 (77%)]\tLoss: 0.227630\nTrain Epoch: 5 [39680/50000 (79%)]\tLoss: 0.230357\nTrain Epoch: 5 [40960/50000 (82%)]\tLoss: 0.201925\nTrain Epoch: 5 [42240/50000 (84%)]\tLoss: 0.232221\nTrain Epoch: 5 [43520/50000 (87%)]\tLoss: 0.230209\nTrain Epoch: 5 [44800/50000 (90%)]\tLoss: 0.201077\nTrain Epoch: 5 [46080/50000 (92%)]\tLoss: 0.198678\nTrain Epoch: 5 [47360/50000 (95%)]\tLoss: 0.192364\nTrain Epoch: 5 [48640/50000 (97%)]\tLoss: 0.214653\nTrain Epoch: 5 [31200/50000 (100%)]\tLoss: 0.216928\nTop 5 Accuracy: 81.16%\n- Best model saved with accuracy: 81.16%\n- Checkpoint saved successfully\nTrain Epoch: 6 [0/50000 (0%)]\tLoss: 0.191831\nTrain Epoch: 6 [1280/50000 (3%)]\tLoss: 0.199809\nTrain Epoch: 6 [2560/50000 (5%)]\tLoss: 0.196526\nTrain Epoch: 6 [3840/50000 (8%)]\tLoss: 0.208410\nTrain Epoch: 6 [5120/50000 (10%)]\tLoss: 0.193572\nTrain Epoch: 6 [6400/50000 (13%)]\tLoss: 0.186825\nTrain Epoch: 6 [7680/50000 (15%)]\tLoss: 0.211553\nTrain Epoch: 6 [8960/50000 (18%)]\tLoss: 0.178490\nTrain Epoch: 6 [10240/50000 (20%)]\tLoss: 0.211883\nTrain Epoch: 6 [11520/50000 (23%)]\tLoss: 0.164785\nTrain Epoch: 6 [12800/50000 (26%)]\tLoss: 0.210511\nTrain Epoch: 6 [14080/50000 (28%)]\tLoss: 0.174385\nTrain Epoch: 6 [15360/50000 (31%)]\tLoss: 0.185317\nTrain Epoch: 6 [16640/50000 (33%)]\tLoss: 0.193812\nTrain Epoch: 6 [17920/50000 (36%)]\tLoss: 0.263982\nTrain Epoch: 6 [20480/50000 (41%)]\tLoss: 0.196357\nTrain Epoch: 6 [21760/50000 (43%)]\tLoss: 0.195370\nTrain Epoch: 6 [23040/50000 (46%)]\tLoss: 0.208055\nTrain Epoch: 6 [24320/50000 (49%)]\tLoss: 0.213786\nTrain Epoch: 6 [25600/50000 (51%)]\tLoss: 0.213359\nTrain Epoch: 6 [26880/50000 (54%)]\tLoss: 0.190921\nTrain Epoch: 6 [28160/50000 (56%)]\tLoss: 0.187095\nTrain Epoch: 6 [29440/50000 (59%)]\tLoss: 0.177682\nTrain Epoch: 6 [30720/50000 (61%)]\tLoss: 0.205619\nTrain Epoch: 6 [32000/50000 (64%)]\tLoss: 0.182973\nTrain Epoch: 6 [33280/50000 (66%)]\tLoss: 0.221639\nTrain Epoch: 6 [34560/50000 (69%)]\tLoss: 0.148072\nTrain Epoch: 6 [35840/50000 (72%)]\tLoss: 0.171038\nTrain Epoch: 6 [37120/50000 (74%)]\tLoss: 0.184496\nTrain Epoch: 6 [38400/50000 (77%)]\tLoss: 0.207624\nTrain Epoch: 6 [39680/50000 (79%)]\tLoss: 0.187346\nTrain Epoch: 6 [40960/50000 (82%)]\tLoss: 0.197135\nTrain Epoch: 6 [42240/50000 (84%)]\tLoss: 0.203612\nTrain Epoch: 6 [43520/50000 (87%)]\tLoss: 0.180598\nTrain Epoch: 6 [44800/50000 (90%)]\tLoss: 0.179152\nTrain Epoch: 6 [46080/50000 (92%)]\tLoss: 0.203440\nTrain Epoch: 6 [47360/50000 (95%)]\tLoss: 0.159540\nTrain Epoch: 6 [48640/50000 (97%)]\tLoss: 0.172144\nTrain Epoch: 6 [31200/50000 (100%)]\tLoss: 0.185610\nTop 5 Accuracy: 79.05%\n- Early stopping trigger times: 1/10\n- Checkpoint saved successfully\nTrain Epoch: 7 [0/50000 (0%)]\tLoss: 0.168753\nTrain Epoch: 7 [1280/50000 (3%)]\tLoss: 0.163276\nTrain Epoch: 7 [2560/50000 (5%)]\tLoss: 0.184644\nTrain Epoch: 7 [3840/50000 (8%)]\tLoss: 0.182237\nTrain Epoch: 7 [5120/50000 (10%)]\tLoss: 0.160130\nTrain Epoch: 7 [6400/50000 (13%)]\tLoss: 0.176793\nTrain Epoch: 7 [7680/50000 (15%)]\tLoss: 0.187706\nTrain Epoch: 7 [8960/50000 (18%)]\tLoss: 0.181325\nTrain Epoch: 7 [10240/50000 (20%)]\tLoss: 0.188146\nTrain Epoch: 7 [11520/50000 (23%)]\tLoss: 0.196909\nTrain Epoch: 7 [12800/50000 (26%)]\tLoss: 0.186775\nTrain Epoch: 7 [14080/50000 (28%)]\tLoss: 0.169791\nTrain Epoch: 7 [15360/50000 (31%)]\tLoss: 0.168038\nTrain Epoch: 7 [16640/50000 (33%)]\tLoss: 0.168887\nTrain Epoch: 7 [17920/50000 (36%)]\tLoss: 0.183919\nTrain Epoch: 7 [19200/50000 (38%)]\tLoss: 0.184500\nTrain Epoch: 7 [20480/50000 (41%)]\tLoss: 0.168140\nTrain Epoch: 7 [21760/50000 (43%)]\tLoss: 0.169973\nTrain Epoch: 7 [23040/50000 (46%)]\tLoss: 0.173923\nTrain Epoch: 7 [24320/50000 (49%)]\tLoss: 0.205706\nTrain Epoch: 7 [25600/50000 (51%)]\tLoss: 0.174682\nTrain Epoch: 7 [26880/50000 (54%)]\tLoss: 0.172145\nTrain Epoch: 7 [28160/50000 (56%)]\tLoss: 0.175898\nTrain Epoch: 7 [29440/50000 (59%)]\tLoss: 0.183152\nTrain Epoch: 7 [30720/50000 (61%)]\tLoss: 0.157874\nTrain Epoch: 7 [32000/50000 (64%)]\tLoss: 0.171696\nTrain Epoch: 7 [33280/50000 (66%)]\tLoss: 0.187591\nTrain Epoch: 7 [34560/50000 (69%)]\tLoss: 0.160312\nTrain Epoch: 7 [35840/50000 (72%)]\tLoss: 0.186035\nTrain Epoch: 7 [37120/50000 (74%)]\tLoss: 0.159901\nTrain Epoch: 7 [38400/50000 (77%)]\tLoss: 0.176701\nTrain Epoch: 7 [39680/50000 (79%)]\tLoss: 0.190524\nTrain Epoch: 7 [40960/50000 (82%)]\tLoss: 0.166270\nTrain Epoch: 7 [42240/50000 (84%)]\tLoss: 0.154135\nTrain Epoch: 7 [43520/50000 (87%)]\tLoss: 0.166155\nTrain Epoch: 7 [44800/50000 (90%)]\tLoss: 0.205839\nTrain Epoch: 7 [46080/50000 (92%)]\tLoss: 0.166662\nTrain Epoch: 7 [47360/50000 (95%)]\tLoss: 0.188525\nTrain Epoch: 7 [48640/50000 (97%)]\tLoss: 0.188532\nTrain Epoch: 7 [31200/50000 (100%)]\tLoss: 0.144480\nTop 5 Accuracy: 85.68%\n- Best model saved with accuracy: 85.68%\n- Checkpoint saved successfully\nTrain Epoch: 8 [0/50000 (0%)]\tLoss: 0.188993\nTrain Epoch: 8 [1280/50000 (3%)]\tLoss: 0.177509\nTrain Epoch: 8 [2560/50000 (5%)]\tLoss: 0.193404\nTrain Epoch: 8 [3840/50000 (8%)]\tLoss: 0.137206\nTrain Epoch: 8 [5120/50000 (10%)]\tLoss: 0.187858\nTrain Epoch: 8 [6400/50000 (13%)]\tLoss: 0.183399\nTrain Epoch: 8 [7680/50000 (15%)]\tLoss: 0.165898\nTrain Epoch: 8 [8960/50000 (18%)]\tLoss: 0.171176\nTrain Epoch: 8 [10240/50000 (20%)]\tLoss: 0.162727\nTrain Epoch: 8 [11520/50000 (23%)]\tLoss: 0.186959\nTrain Epoch: 8 [12800/50000 (26%)]\tLoss: 0.167676\nTrain Epoch: 8 [14080/50000 (28%)]\tLoss: 0.172545\nTrain Epoch: 8 [15360/50000 (31%)]\tLoss: 0.216691\nTrain Epoch: 8 [16640/50000 (33%)]\tLoss: 0.194015\nTrain Epoch: 8 [17920/50000 (36%)]\tLoss: 0.191524\nTrain Epoch: 8 [19200/50000 (38%)]\tLoss: 0.159086\nTrain Epoch: 8 [20480/50000 (41%)]\tLoss: 0.169296\nTrain Epoch: 8 [21760/50000 (43%)]\tLoss: 0.214020\nTrain Epoch: 8 [23040/50000 (46%)]\tLoss: 0.161671\nTrain Epoch: 8 [24320/50000 (49%)]\tLoss: 0.147774\nTrain Epoch: 8 [25600/50000 (51%)]\tLoss: 0.156568\nTrain Epoch: 8 [26880/50000 (54%)]\tLoss: 0.164531\nTrain Epoch: 8 [28160/50000 (56%)]\tLoss: 0.132274\nTrain Epoch: 8 [29440/50000 (59%)]\tLoss: 0.182072\nTrain Epoch: 8 [30720/50000 (61%)]\tLoss: 0.152287\nTrain Epoch: 8 [32000/50000 (64%)]\tLoss: 0.196365\nTrain Epoch: 8 [33280/50000 (66%)]\tLoss: 0.139700\nTrain Epoch: 8 [34560/50000 (69%)]\tLoss: 0.169933\nTrain Epoch: 8 [35840/50000 (72%)]\tLoss: 0.160868\nTrain Epoch: 8 [37120/50000 (74%)]\tLoss: 0.166181\nTrain Epoch: 8 [38400/50000 (77%)]\tLoss: 0.181382\nTrain Epoch: 8 [39680/50000 (79%)]\tLoss: 0.175985\nTrain Epoch: 8 [40960/50000 (82%)]\tLoss: 0.180268\nTrain Epoch: 8 [42240/50000 (84%)]\tLoss: 0.179253\nTrain Epoch: 8 [43520/50000 (87%)]\tLoss: 0.169371\nTrain Epoch: 8 [44800/50000 (90%)]\tLoss: 0.208641\nTrain Epoch: 8 [46080/50000 (92%)]\tLoss: 0.148533\nTrain Epoch: 8 [47360/50000 (95%)]\tLoss: 0.188342\nTrain Epoch: 8 [48640/50000 (97%)]\tLoss: 0.181233\nTrain Epoch: 8 [31200/50000 (100%)]\tLoss: 0.183252\nTop 5 Accuracy: 86.95%\n- Best model saved with accuracy: 86.95%\n- Checkpoint saved successfully\nTrain Epoch: 9 [0/50000 (0%)]\tLoss: 0.140587\nTrain Epoch: 9 [1280/50000 (3%)]\tLoss: 0.146313\nTrain Epoch: 9 [2560/50000 (5%)]\tLoss: 0.161035\nTrain Epoch: 9 [3840/50000 (8%)]\tLoss: 0.163816\nTrain Epoch: 9 [5120/50000 (10%)]\tLoss: 0.166517\nTrain Epoch: 9 [6400/50000 (13%)]\tLoss: 0.179870\nTrain Epoch: 9 [7680/50000 (15%)]\tLoss: 0.180243\nTrain Epoch: 9 [8960/50000 (18%)]\tLoss: 0.148255\nTrain Epoch: 9 [10240/50000 (20%)]\tLoss: 0.146086\nTrain Epoch: 9 [11520/50000 (23%)]\tLoss: 0.166461\nTrain Epoch: 9 [12800/50000 (26%)]\tLoss: 0.158464\nTrain Epoch: 9 [14080/50000 (28%)]\tLoss: 0.150638\nTrain Epoch: 9 [15360/50000 (31%)]\tLoss: 0.181036\nTrain Epoch: 9 [16640/50000 (33%)]\tLoss: 0.181026\nTrain Epoch: 9 [17920/50000 (36%)]\tLoss: 0.193534\nTrain Epoch: 9 [19200/50000 (38%)]\tLoss: 0.205655\nTrain Epoch: 9 [20480/50000 (41%)]\tLoss: 0.131694\nTrain Epoch: 9 [21760/50000 (43%)]\tLoss: 0.176987\nTrain Epoch: 9 [23040/50000 (46%)]\tLoss: 0.141682\nTrain Epoch: 9 [24320/50000 (49%)]\tLoss: 0.154198\nTrain Epoch: 9 [25600/50000 (51%)]\tLoss: 0.167387\nTrain Epoch: 9 [26880/50000 (54%)]\tLoss: 0.130063\nTrain Epoch: 9 [28160/50000 (56%)]\tLoss: 0.145561\nTrain Epoch: 9 [29440/50000 (59%)]\tLoss: 0.127993\nTrain Epoch: 9 [30720/50000 (61%)]\tLoss: 0.159193\nTrain Epoch: 9 [32000/50000 (64%)]\tLoss: 0.170527\nTrain Epoch: 9 [33280/50000 (66%)]\tLoss: 0.137145\nTrain Epoch: 9 [34560/50000 (69%)]\tLoss: 0.150455\nTrain Epoch: 9 [35840/50000 (72%)]\tLoss: 0.154828\nTrain Epoch: 9 [37120/50000 (74%)]\tLoss: 0.169487\nTrain Epoch: 9 [38400/50000 (77%)]\tLoss: 0.173455\nTrain Epoch: 9 [39680/50000 (79%)]\tLoss: 0.176295\nTrain Epoch: 9 [40960/50000 (82%)]\tLoss: 0.129833\nTrain Epoch: 9 [42240/50000 (84%)]\tLoss: 0.150447\nTrain Epoch: 9 [43520/50000 (87%)]\tLoss: 0.115385\nTrain Epoch: 9 [44800/50000 (90%)]\tLoss: 0.150896\nTrain Epoch: 9 [46080/50000 (92%)]\tLoss: 0.191428\nTrain Epoch: 9 [47360/50000 (95%)]\tLoss: 0.139113\nTrain Epoch: 9 [48640/50000 (97%)]\tLoss: 0.131666\nTrain Epoch: 9 [31200/50000 (100%)]\tLoss: 0.168205\nTop 5 Accuracy: 90.53%\n- Best model saved with accuracy: 90.53%\n- Checkpoint saved successfully\nTrain Epoch: 10 [0/50000 (0%)]\tLoss: 0.123523\nTrain Epoch: 10 [1280/50000 (3%)]\tLoss: 0.179289\nTrain Epoch: 10 [2560/50000 (5%)]\tLoss: 0.153050\nTrain Epoch: 10 [3840/50000 (8%)]\tLoss: 0.127190\nTrain Epoch: 10 [5120/50000 (10%)]\tLoss: 0.150489\nTrain Epoch: 10 [6400/50000 (13%)]\tLoss: 0.164764\nTrain Epoch: 10 [7680/50000 (15%)]\tLoss: 0.120689\nTrain Epoch: 10 [8960/50000 (18%)]\tLoss: 0.144093\nTrain Epoch: 10 [10240/50000 (20%)]\tLoss: 0.144272\nTrain Epoch: 10 [11520/50000 (23%)]\tLoss: 0.171222\nTrain Epoch: 10 [12800/50000 (26%)]\tLoss: 0.145433\nTrain Epoch: 10 [14080/50000 (28%)]\tLoss: 0.172545\nTrain Epoch: 10 [15360/50000 (31%)]\tLoss: 0.142910\nTrain Epoch: 10 [16640/50000 (33%)]\tLoss: 0.159282\nTrain Epoch: 10 [17920/50000 (36%)]\tLoss: 0.173011\nTrain Epoch: 10 [19200/50000 (38%)]\tLoss: 0.135746\nTrain Epoch: 10 [20480/50000 (41%)]\tLoss: 0.155647\nTrain Epoch: 10 [21760/50000 (43%)]\tLoss: 0.161211\nTrain Epoch: 10 [23040/50000 (46%)]\tLoss: 0.138057\nTrain Epoch: 10 [24320/50000 (49%)]\tLoss: 0.135289\nTrain Epoch: 10 [25600/50000 (51%)]\tLoss: 0.124775\nTrain Epoch: 10 [26880/50000 (54%)]\tLoss: 0.137844\nTrain Epoch: 10 [28160/50000 (56%)]\tLoss: 0.132221\nTrain Epoch: 10 [29440/50000 (59%)]\tLoss: 0.135996\nTrain Epoch: 10 [30720/50000 (61%)]\tLoss: 0.139619\nTrain Epoch: 10 [32000/50000 (64%)]\tLoss: 0.159175\nTrain Epoch: 10 [33280/50000 (66%)]\tLoss: 0.122232\nTrain Epoch: 10 [34560/50000 (69%)]\tLoss: 0.158075\nTrain Epoch: 10 [35840/50000 (72%)]\tLoss: 0.135372\nTrain Epoch: 10 [37120/50000 (74%)]\tLoss: 0.178375\nTrain Epoch: 10 [38400/50000 (77%)]\tLoss: 0.139158\nTrain Epoch: 10 [39680/50000 (79%)]\tLoss: 0.136344\nTrain Epoch: 10 [40960/50000 (82%)]\tLoss: 0.158863\nTrain Epoch: 10 [42240/50000 (84%)]\tLoss: 0.121480\nTrain Epoch: 10 [43520/50000 (87%)]\tLoss: 0.184065\nTrain Epoch: 10 [44800/50000 (90%)]\tLoss: 0.135123\nTrain Epoch: 10 [46080/50000 (92%)]\tLoss: 0.119412\nTrain Epoch: 10 [47360/50000 (95%)]\tLoss: 0.114870\nTrain Epoch: 10 [48640/50000 (97%)]\tLoss: 0.126962\nTrain Epoch: 10 [31200/50000 (100%)]\tLoss: 0.173733\nTop 5 Accuracy: 90.32%\n- Early stopping trigger times: 1/10\n- Checkpoint saved successfully\nTrain Epoch: 11 [0/50000 (0%)]\tLoss: 0.155290\nTrain Epoch: 11 [1280/50000 (3%)]\tLoss: 0.118535\nTrain Epoch: 11 [2560/50000 (5%)]\tLoss: 0.137193\nTrain Epoch: 11 [3840/50000 (8%)]\tLoss: 0.128451\nTrain Epoch: 11 [5120/50000 (10%)]\tLoss: 0.115450\nTrain Epoch: 11 [6400/50000 (13%)]\tLoss: 0.131278\nTrain Epoch: 11 [7680/50000 (15%)]\tLoss: 0.160158\nTrain Epoch: 11 [8960/50000 (18%)]\tLoss: 0.120552\nTrain Epoch: 11 [10240/50000 (20%)]\tLoss: 0.162363\nTrain Epoch: 11 [11520/50000 (23%)]\tLoss: 0.162646\nTrain Epoch: 11 [12800/50000 (26%)]\tLoss: 0.176490\nTrain Epoch: 11 [14080/50000 (28%)]\tLoss: 0.141389\nTrain Epoch: 11 [15360/50000 (31%)]\tLoss: 0.147685\nTrain Epoch: 11 [16640/50000 (33%)]\tLoss: 0.131489\nTrain Epoch: 11 [17920/50000 (36%)]\tLoss: 0.106057\nTrain Epoch: 11 [19200/50000 (38%)]\tLoss: 0.141963\nTrain Epoch: 11 [20480/50000 (41%)]\tLoss: 0.164328\nTrain Epoch: 11 [21760/50000 (43%)]\tLoss: 0.128466\nTrain Epoch: 11 [23040/50000 (46%)]\tLoss: 0.129581\nTrain Epoch: 11 [24320/50000 (49%)]\tLoss: 0.136709\nTrain Epoch: 11 [25600/50000 (51%)]\tLoss: 0.132200\nTrain Epoch: 11 [26880/50000 (54%)]\tLoss: 0.156528\nTrain Epoch: 11 [28160/50000 (56%)]\tLoss: 0.106728\nTrain Epoch: 11 [29440/50000 (59%)]\tLoss: 0.143555\nTrain Epoch: 11 [30720/50000 (61%)]\tLoss: 0.121336\nTrain Epoch: 11 [32000/50000 (64%)]\tLoss: 0.128278\nTrain Epoch: 11 [33280/50000 (66%)]\tLoss: 0.119973\nTrain Epoch: 11 [34560/50000 (69%)]\tLoss: 0.139645\nTrain Epoch: 11 [35840/50000 (72%)]\tLoss: 0.164780\nTrain Epoch: 11 [37120/50000 (74%)]\tLoss: 0.128231\nTrain Epoch: 11 [38400/50000 (77%)]\tLoss: 0.136130\nTrain Epoch: 11 [39680/50000 (79%)]\tLoss: 0.138205\nTrain Epoch: 11 [40960/50000 (82%)]\tLoss: 0.131079\nTrain Epoch: 11 [42240/50000 (84%)]\tLoss: 0.129299\nTrain Epoch: 11 [43520/50000 (87%)]\tLoss: 0.142187\nTrain Epoch: 11 [44800/50000 (90%)]\tLoss: 0.143932\nTrain Epoch: 11 [46080/50000 (92%)]\tLoss: 0.142035\nTrain Epoch: 11 [47360/50000 (95%)]\tLoss: 0.166619\nTrain Epoch: 11 [48640/50000 (97%)]\tLoss: 0.151904\nTrain Epoch: 11 [31200/50000 (100%)]\tLoss: 0.124860\nTop 5 Accuracy: 91.47%\n- Best model saved with accuracy: 91.47%\n- Checkpoint saved successfully\nTrain Epoch: 12 [0/50000 (0%)]\tLoss: 0.134063\nTrain Epoch: 12 [1280/50000 (3%)]\tLoss: 0.137460\nTrain Epoch: 12 [2560/50000 (5%)]\tLoss: 0.148412\nTrain Epoch: 12 [3840/50000 (8%)]\tLoss: 0.138988\nTrain Epoch: 12 [5120/50000 (10%)]\tLoss: 0.151802\nTrain Epoch: 12 [6400/50000 (13%)]\tLoss: 0.140147\nTrain Epoch: 12 [7680/50000 (15%)]\tLoss: 0.168187\nTrain Epoch: 12 [8960/50000 (18%)]\tLoss: 0.125622\nTrain Epoch: 12 [10240/50000 (20%)]\tLoss: 0.126905\nTrain Epoch: 12 [11520/50000 (23%)]\tLoss: 0.154585\nTrain Epoch: 12 [12800/50000 (26%)]\tLoss: 0.153079\nTrain Epoch: 12 [14080/50000 (28%)]\tLoss: 0.161344\nTrain Epoch: 12 [15360/50000 (31%)]\tLoss: 0.150566\nTrain Epoch: 12 [16640/50000 (33%)]\tLoss: 0.125311\nTrain Epoch: 12 [17920/50000 (36%)]\tLoss: 0.132176\nTrain Epoch: 12 [19200/50000 (38%)]\tLoss: 0.117822\nTrain Epoch: 12 [20480/50000 (41%)]\tLoss: 0.098043\nTrain Epoch: 12 [21760/50000 (43%)]\tLoss: 0.134993\nTrain Epoch: 12 [23040/50000 (46%)]\tLoss: 0.136431\nTrain Epoch: 12 [24320/50000 (49%)]\tLoss: 0.121477\nTrain Epoch: 12 [25600/50000 (51%)]\tLoss: 0.122417\nTrain Epoch: 12 [26880/50000 (54%)]\tLoss: 0.133404\nTrain Epoch: 12 [28160/50000 (56%)]\tLoss: 0.125654\nTrain Epoch: 12 [29440/50000 (59%)]\tLoss: 0.167774\nTrain Epoch: 12 [30720/50000 (61%)]\tLoss: 0.156327\nTrain Epoch: 12 [32000/50000 (64%)]\tLoss: 0.128097\nTrain Epoch: 12 [33280/50000 (66%)]\tLoss: 0.119763\nTrain Epoch: 12 [34560/50000 (69%)]\tLoss: 0.141618\nTrain Epoch: 12 [35840/50000 (72%)]\tLoss: 0.117844\nTrain Epoch: 12 [37120/50000 (74%)]\tLoss: 0.135815\nTrain Epoch: 12 [38400/50000 (77%)]\tLoss: 0.135534\nTrain Epoch: 12 [39680/50000 (79%)]\tLoss: 0.144336\nTrain Epoch: 12 [40960/50000 (82%)]\tLoss: 0.171737\nTrain Epoch: 12 [42240/50000 (84%)]\tLoss: 0.090093\nTrain Epoch: 12 [43520/50000 (87%)]\tLoss: 0.149888\nTrain Epoch: 12 [44800/50000 (90%)]\tLoss: 0.134378\nTrain Epoch: 12 [46080/50000 (92%)]\tLoss: 0.142668\nTrain Epoch: 12 [47360/50000 (95%)]\tLoss: 0.125049\nTrain Epoch: 12 [48640/50000 (97%)]\tLoss: 0.117461\nTrain Epoch: 12 [31200/50000 (100%)]\tLoss: 0.138573\nTop 5 Accuracy: 92.32%\n- Best model saved with accuracy: 92.32%\n- Checkpoint saved successfully\nTrain Epoch: 13 [0/50000 (0%)]\tLoss: 0.142453\nTrain Epoch: 13 [1280/50000 (3%)]\tLoss: 0.110770\nTrain Epoch: 13 [2560/50000 (5%)]\tLoss: 0.102924\nTrain Epoch: 13 [3840/50000 (8%)]\tLoss: 0.122097\nTrain Epoch: 13 [5120/50000 (10%)]\tLoss: 0.102572\nTrain Epoch: 13 [6400/50000 (13%)]\tLoss: 0.123971\nTrain Epoch: 13 [7680/50000 (15%)]\tLoss: 0.149884\nTrain Epoch: 13 [8960/50000 (18%)]\tLoss: 0.134809\nTrain Epoch: 13 [10240/50000 (20%)]\tLoss: 0.135788\nTrain Epoch: 13 [11520/50000 (23%)]\tLoss: 0.134592\nTrain Epoch: 13 [12800/50000 (26%)]\tLoss: 0.142893\nTrain Epoch: 13 [14080/50000 (28%)]\tLoss: 0.110479\nTrain Epoch: 13 [15360/50000 (31%)]\tLoss: 0.110911\nTrain Epoch: 13 [16640/50000 (33%)]\tLoss: 0.136430\nTrain Epoch: 13 [17920/50000 (36%)]\tLoss: 0.106699\nTrain Epoch: 13 [19200/50000 (38%)]\tLoss: 0.138813\nTrain Epoch: 13 [20480/50000 (41%)]\tLoss: 0.132849\nTrain Epoch: 13 [21760/50000 (43%)]\tLoss: 0.102275\nTrain Epoch: 13 [23040/50000 (46%)]\tLoss: 0.116931\nTrain Epoch: 13 [24320/50000 (49%)]\tLoss: 0.129498\nTrain Epoch: 13 [25600/50000 (51%)]\tLoss: 0.142742\nTrain Epoch: 13 [26880/50000 (54%)]\tLoss: 0.126302\nTrain Epoch: 13 [28160/50000 (56%)]\tLoss: 0.124385\nTrain Epoch: 13 [29440/50000 (59%)]\tLoss: 0.135489\nTrain Epoch: 13 [30720/50000 (61%)]\tLoss: 0.135024\nTrain Epoch: 13 [32000/50000 (64%)]\tLoss: 0.139532\nTrain Epoch: 13 [33280/50000 (66%)]\tLoss: 0.164448\nTrain Epoch: 13 [34560/50000 (69%)]\tLoss: 0.129579\nTrain Epoch: 13 [35840/50000 (72%)]\tLoss: 0.139285\nTrain Epoch: 13 [37120/50000 (74%)]\tLoss: 0.121552\nTrain Epoch: 13 [38400/50000 (77%)]\tLoss: 0.126603\nTrain Epoch: 13 [39680/50000 (79%)]\tLoss: 0.121673\nTrain Epoch: 13 [40960/50000 (82%)]\tLoss: 0.155775\nTrain Epoch: 13 [42240/50000 (84%)]\tLoss: 0.124240\nTrain Epoch: 13 [43520/50000 (87%)]\tLoss: 0.119449\nTrain Epoch: 13 [44800/50000 (90%)]\tLoss: 0.135116\nTrain Epoch: 13 [46080/50000 (92%)]\tLoss: 0.113127\nTrain Epoch: 13 [47360/50000 (95%)]\tLoss: 0.138560\nTrain Epoch: 13 [48640/50000 (97%)]\tLoss: 0.123499\nTrain Epoch: 13 [31200/50000 (100%)]\tLoss: 0.071828\nTop 5 Accuracy: 92.21%\n- Early stopping trigger times: 1/10\n- Checkpoint saved successfully\nTrain Epoch: 14 [0/50000 (0%)]\tLoss: 0.092420\nTrain Epoch: 14 [1280/50000 (3%)]\tLoss: 0.133377\nTrain Epoch: 14 [2560/50000 (5%)]\tLoss: 0.150686\nTrain Epoch: 14 [3840/50000 (8%)]\tLoss: 0.101953\nTrain Epoch: 14 [5120/50000 (10%)]\tLoss: 0.142121\nTrain Epoch: 14 [6400/50000 (13%)]\tLoss: 0.100191\nTrain Epoch: 14 [7680/50000 (15%)]\tLoss: 0.124345\nTrain Epoch: 14 [8960/50000 (18%)]\tLoss: 0.124886\nTrain Epoch: 14 [10240/50000 (20%)]\tLoss: 0.131706\nTrain Epoch: 14 [11520/50000 (23%)]\tLoss: 0.093907\nTrain Epoch: 14 [12800/50000 (26%)]\tLoss: 0.130004\nTrain Epoch: 14 [14080/50000 (28%)]\tLoss: 0.112646\nTrain Epoch: 14 [15360/50000 (31%)]\tLoss: 0.105185\nTrain Epoch: 14 [16640/50000 (33%)]\tLoss: 0.138832\nTrain Epoch: 14 [17920/50000 (36%)]\tLoss: 0.155332\nTrain Epoch: 14 [19200/50000 (38%)]\tLoss: 0.142158\nTrain Epoch: 14 [20480/50000 (41%)]\tLoss: 0.123779\nTrain Epoch: 14 [21760/50000 (43%)]\tLoss: 0.100386\nTrain Epoch: 14 [23040/50000 (46%)]\tLoss: 0.105856\nTrain Epoch: 14 [24320/50000 (49%)]\tLoss: 0.095169\nTrain Epoch: 14 [25600/50000 (51%)]\tLoss: 0.142097\nTrain Epoch: 14 [26880/50000 (54%)]\tLoss: 0.110241\nTrain Epoch: 14 [28160/50000 (56%)]\tLoss: 0.121532\nTrain Epoch: 14 [29440/50000 (59%)]\tLoss: 0.136165\nTrain Epoch: 14 [30720/50000 (61%)]\tLoss: 0.120359\nTrain Epoch: 14 [32000/50000 (64%)]\tLoss: 0.136838\nTrain Epoch: 14 [33280/50000 (66%)]\tLoss: 0.088411\nTrain Epoch: 14 [34560/50000 (69%)]\tLoss: 0.114392\nTrain Epoch: 14 [35840/50000 (72%)]\tLoss: 0.123973\nTrain Epoch: 14 [37120/50000 (74%)]\tLoss: 0.094226\nTrain Epoch: 14 [38400/50000 (77%)]\tLoss: 0.127175\nTrain Epoch: 14 [39680/50000 (79%)]\tLoss: 0.102973\nTrain Epoch: 14 [40960/50000 (82%)]\tLoss: 0.114852\nTrain Epoch: 14 [42240/50000 (84%)]\tLoss: 0.091345\nTrain Epoch: 14 [43520/50000 (87%)]\tLoss: 0.124460\nTrain Epoch: 14 [44800/50000 (90%)]\tLoss: 0.130166\nTrain Epoch: 14 [46080/50000 (92%)]\tLoss: 0.124547\nTrain Epoch: 14 [47360/50000 (95%)]\tLoss: 0.107549\nTrain Epoch: 14 [48640/50000 (97%)]\tLoss: 0.111736\nTrain Epoch: 14 [31200/50000 (100%)]\tLoss: 0.111478\nTop 5 Accuracy: 91.79%\n- Early stopping trigger times: 2/10\n- Checkpoint saved successfully\nTrain Epoch: 15 [0/50000 (0%)]\tLoss: 0.118470\nTrain Epoch: 15 [1280/50000 (3%)]\tLoss: 0.137370\nTrain Epoch: 15 [2560/50000 (5%)]\tLoss: 0.147454\nTrain Epoch: 15 [3840/50000 (8%)]\tLoss: 0.094839\nTrain Epoch: 15 [5120/50000 (10%)]\tLoss: 0.102846\nTrain Epoch: 15 [6400/50000 (13%)]\tLoss: 0.114565\nTrain Epoch: 15 [7680/50000 (15%)]\tLoss: 0.136833\nTrain Epoch: 15 [8960/50000 (18%)]\tLoss: 0.119874\nTrain Epoch: 15 [10240/50000 (20%)]\tLoss: 0.124195\nTrain Epoch: 15 [11520/50000 (23%)]\tLoss: 0.137875\nTrain Epoch: 15 [12800/50000 (26%)]\tLoss: 0.132526\nTrain Epoch: 15 [14080/50000 (28%)]\tLoss: 0.128232\nTrain Epoch: 15 [15360/50000 (31%)]\tLoss: 0.099875\nTrain Epoch: 15 [16640/50000 (33%)]\tLoss: 0.115932\nTrain Epoch: 15 [17920/50000 (36%)]\tLoss: 0.117167\nTrain Epoch: 15 [19200/50000 (38%)]\tLoss: 0.115108\nTrain Epoch: 15 [20480/50000 (41%)]\tLoss: 0.100919\nTrain Epoch: 15 [21760/50000 (43%)]\tLoss: 0.089683\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}